\documentclass[12pt, a4paper]{book}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[main=italian]{babel}
\usepackage{bookmark}
\usepackage[a4paper, total={6in, 9in}]{geometry}
\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage{tikz}
\usepackage{caption}
\usepackage{tikz-network}
\usepackage{float}
\floatplacement{figure}{H}

\theoremstyle{theorem}
\newtheorem{definition}{Definizione}[section]
\newtheorem{theorem}{Teorema}[section]

\begin{document}
	\begin{titlepage}
		\centering % Center everything on the title page
		\scshape % Use small caps for all text on the title page
		Appunti dal Corso di
		\vspace*{1.5\baselineskip} % White space at the top of the page
		% ===================
		% Title Section
		% ===================
		
		
		
		\rule{13cm}{1.6pt}\vspace*{-\baselineskip}\vspace*{2pt} % Thick horizontal rule
		\rule{13cm}{0.4pt} % Thin horizontal rule
		
		\vspace{0.75\baselineskip} % Whitespace above the title
		% ========== Title ===============
		{ \Huge Introduzione alla Fisica\\
		\vspace{4mm}
		dei Sistemi Complessi \\ }
		% ======================================
		\vspace{0.75\baselineskip} % Whitespace below the title
		\rule{13cm}{0.4pt}\vspace*{-\baselineskip}\vspace{3.2pt} % Thin horizontal rule
		\rule{13cm}{1.6pt} % Thick horizontal rule
		
		\vspace{1.75\baselineskip} % Whitespace after the title block
		% =================
		% Information
		% =================
		{}
		Berselli Gregorio \quad Lanzi Samuele
		\vfill
	\end{titlepage}
	\tableofcontents
	\chapter{Introduzione} %CAPITOLO 1
		\section{Sistema Complesso}
			\begin{definition}
				\textit{Sistema Complesso} è un sistema dinamico composto da sottosistemi interagenti tra loro, chiamati agenti.
			\end{definition}
			Per lo studio di un sistema complesso si usa solitamente un approccio olistico, ossia ssi studiano prevalentemente le proprietà macroscopiche del sistema totale, senza considerare i singoli sottosistemi.
			Un'osservazione importante che va effettuata è che un sistema complesso \textbf{prevede}, non descrive.
			\begin{definition}
				Lo spazio degli stati dinamici del sistema è detto spazio delle fasi.
			\end{definition}
			\begin{definition}
				I gradi di libertà di un sistema sono dati da $\# d.o.f.=\frac{dimensione dello spazio}{2}$
			\end{definition}
			Per un numero elevato di gradi di libertà è possibile utilizzare l'approccio della meccanica statistica.
			Alcune delle proprietà principali dei sistemi complessi sono:
			\begin{itemize}
				\item \textbf{complessità}: presenza di molti d.o.f. (molti agenti)
				\item \textbf{proprietà emergenti}: derivano dal grande numero di agenti. Ad esempio possiamo definire \textit{fluido} un insieme di molte particelle ma la particella singola non può essere fluida.
				\item \textbf{autorganizzazione}: i sistemi complessi sono ibridi, ossia metà stocastici e metà deterministici. Per studiarli devo dare ugual peso a entrambi gli aspetti.
			\end{itemize}
			La complessità dei sistemi fa si che per definirne uno stato occorra molta \emph{informazione}.
			Ogni sistema complesso fornisce un \emph{feedback} rispetto alle condizioni inziali che sono fornite.
			In particolare, si parla di \emph{feedback positivo} se le condizioni iniziali portano il sistema a "esplodere", ossia ad allontanarsi inesorabilmente dall'origine, mentre si parla di \emph{feedback negativo} quando dopo un certo periodo di tempo il sistema ritorna alle condizioni iniziali.
			\begin{definition}
				Un sistema a feedback negativo è detto in equilibrio dinamico.
			\end{definition}
		
		\section{Teoria di Ljapunov}
			In un sistema classico, una volta scritta la lagrangiana (o hamiltoniana) del sistema e ottenute le \emph{equazioni del moto}, è cosa fatta determinarne l'evoluzione nel tempo (traiettorie).
			Nei sistemi complessi, tuttavia, non è possibile utilizzare un approccio deterministico: si parla infatti di \emph{caos deterministico}.
			Questo caos è causato soprattutto dalle fluttuazioni intrinseche dei sistemi complessi, le quali li rendono particolamente sensibili alle condizioni iniziali.
			Si consideri sistema alle condizioni iniziali $x_{0}$.
			Dopo un tempo $t$, si troverà naturalmente il sistema in una posizione $x(t)$ determinata dalle condizioni iniziali.
			Si assuma ora la presenza di fluttuazioni sulle condizioni iniziali $x_{0}+\delta_{0}$: il sistema evolverà ora come $x(t)+\delta(t)$.
			La teoria vuole che le fluttuazioni seguano l'andamento
			\begin{equation}
				\delta(t)\simeq\delta_{0}e^{\lambda t}
			\end{equation}
			dove il coefficiente $\lambda$ è detto \emph{esponente di Ljapunov}.
			Il calcolo di questo parametro non è banale, pertanto non verrà dimostrato ma solo riportato.
			\begin{theorem}
				$\lambda=\lim_{\delta\to0,t\to\infty}\frac{1}{t}\ln\left\lVert \Phi^{t}(x+\delta)-\Phi^{t}(x) \right\rVert$
			\end{theorem}
			Nonostante il calcolo precedente possa spaventare, nella maggior parte dei casi si può utilizzare l'approssimazione $\lambda\simeq\frac{1}{t}\sum_{k}\ln\frac{\delta_{k}}{\delta_{0}}$, dove $k$ indicizza una traslazione temporale $\Delta t$. 
			Per comprendere i limiti dell'approssimazione precedente si può notare come $\delta_{0}e^{\lambda t}=o(1)$, quindi $\ln\delta_{0}+\lambda t=0$.
			\begin{definition}
				$t=-\frac{\ln\delta_{0}}{\lambda}$ tempo di predittività del modello	
			\end{definition}
			Si può notare come:
			\begin{itemize}
				\item l'esponente di Ljapunov è una proprietà dell'orbita, non del punto, ed è quindi necessario interagire su tempi lunghi;
				\item un'alta sensibiltà alle condizioni iniziali implica una scarsa predittività;
				\item per $\lambda>>1$ è possibile utilizzare l'approccio statistico;
				\item le proprietà sono locali (ma non così tanto locali).
			\end{itemize}
			Non è possibile conoscere a priori il segno di $\lambda$.
			Il \emph{caos deterministico}, ovviamente, si ottiene solo se $\lambda>0$ (l'esponenziale esplode) in un insieme a misura finita.
			Ne consegue che le orbite debbano espandersi rimanendo limitate, fenomeno noto come \emph{stretching-folding}, e quindi la conservazione di una misura (volume).
			\begin{theorem}
				di Poincarè (del ritorno)
				\\Un sistema dinamico che conserva i volumi su un compatto ritorna arbitrariamente vicino alle condizioni iniziali (feedback negativo).
				\label{theorem:poincare}
			\end{theorem}
		
		\section{Costruzione di un modello}
			Punto fondamentale di un sistema complesso è costruire un modello che riesca a riprodurre le sue caratteristiche fondamentali, per poi studiarlo.
			Innanzitutto, per prevedere un sistema occorre:
			\begin{itemize}
				\item un modello (matematico) per l'evoluzione;
				\item una conoscenza dello stato presente (o passato) del sistema \emph{sufficiente} ad inizializzare il modello;
			\end{itemize}
			Si possono distinguere due tipologie di modelli, le quali verranno ora analizzate.
			\subsection{Modelli ad agente}
				La prima tipologia di modello sono i \emph{modelli ad agente}, ossia quei modelli in cui si effettua uno stduio di tipo bottom-up (dal particolare al generale).
				Assunzione fondamentale è di avere piena conoscenza sui comportamenti dei singoli agenti e sull'ambiente in cui questi si relazionano.
				Una volta \emph{formalizzati} matematicamente i comportamenti dei singoli è possibile procedere con una \emph{simulazione}, la quale fornirà una possibile evoluzione del sistema.
				È essenziale notare come in questo caso il risultato ottenuto sia solamente uno dei tanti possibili: bisognerà quindi effettuare la simulazione numerose volte e mediare sui risultati ottenuti.
				Riguardo la costruzione del modello, la prima cosa da definire è l'\textit{ambiente} in cui ci si trova. 
				Questo può essere neutro o avere caratteristiche, ad esempio una distribuzione di nutrimento (per sistemi biologici).
				Altro punto fondamentale è definire \textit{spazio e tempo}. 
				Spesso non fa differenza la scelta di spazi e tempi discreti rispetto ai continui, quindi è preferibile assumere una discretizzazione iniziale per poi passare al continuo successivamente.
				Una volta definito lo spazio bisogna poi decidere le condizioni al contorno, ossia il comportamento ai bordi. 
				Si possono avere \textit{barriere} di tre tipi:
				\begin{itemize}
					\item \textbf{riflettenti}, dove si ha un bordo \textit{non} oltrepassabile. Si crea quindi un fenomeno di \textbf{attrattività delle pareti}.
					\item \textbf{periodico}, dove si hanno i bordi coincidenti (esco da una parte e rientro dall'altra). Lo spazio assume in questo caso una forma toroidale.
					\item \textbf{assorbenti}, dove gli oggetti "uscenti" vengono distrutti. In questo caso bisogna di introdurre delle \textit{sorgenti} nel modello per evitare di perdere tutti gli agenti.
				\end{itemize}
				Si nota facilmente come più piccolo sia il modello, più importante sia il contributo degli effetti di bordo.\\
				Nella maggior parte dei sistemi non tutti gli agenti hanno le stesse caratteristiche: si definiscono allora \textbf{classi} di appartenenza, legate tra loro da relazioni matematiche.
			\subsection{Modelli a equazioni}
				La seconda ed ultima tipologia di sistema complesso è data dai \emph{modelli a equazioni}, ossia quei modelli in cui si effettua uno stduio di tipo top-down (dal generale al particolare).
				In questo caso si assume di non avere conoscenza sui singoli agenti ma di possedere informazioni di carattere puramente macroscopico, dette \emph{osservabili} del sistema.
				Tipicamente, gli osservabili sono legati tra di loro tramite equazioni differenziali le quali, una volta integrate, forniscono un'evoluzione del sistema nel tempo.
				In questo caso il risultato ottenuto rappresenta già una media di tutti i risultati possibili: le fluttuazioni del sistema provocheranno quindi uno scostamento da questo valore.
				Ovviamente, più tempo si farà evolvere il sistema, più rilevante sarà l'effetto delle fluttuazioni e meno preciso sarà il risultato della previsione.

		\section{Esempi}
			\subsection{Random Walk 1D}
				Il modello più basilare di sistema complesso è sicuramente la random walk su una retta, ossia un punto che ogni istante di tempo decide in maniera casuale se spostarsi a destra o a sinistra.
				Sia $p=\frac{1}{2}$ la probabilità di muoversi verso destra (quindi anche a sinistra) di un passo $\Delta x$. Si hanno:
				\begin{itemize}
					\item \{R\}: $p(t+\Delta t)=x(t)+\Delta x$
					\item \{L\}: $p(t+\Delta t)=x(t)-\Delta x$
				\end{itemize}
				Dopo \textit{n} passi si ha quindi $p(n\Delta t)=x_0+\sum_k\xi_k\Delta x$ con $\xi(t)=\pm 1$.
				Inoltre si può verificare che $<\xi_k>=0$, $<\xi_k^2>=1$, $<\xi_k\xi_h>=<\xi_k><\xi_h>, k\neq h$.
				Per il teorema del limite centrale si ha:
				$\sum_k^n\xi_k\Delta x=\sqrt{n\Delta t}\left(\frac{1}{\sqrt{n}}\sum_k^n\xi_k\right)\frac{\Delta x}{\sqrt{\Delta t}}=\frac{1}{\sqrt{2\pi Dt}}e^{-\frac{z^2}{2Dt}}$, con $z$ variabile gaussiana.
				Introducendo il concetto di diffusione:\\
				\begin{definition}
					Diffusione. $D=\frac{\Delta x^2}{\Delta t}$
				\end{definition}
				si può descrivere l'evoluzione del sistema come $x(t)=x_0+z\sqrt{Dt}$
				Si utilizza $\sqrt{n}$ per normalizzare in quanto è l'unico esponente non divergente.
				La varianza della gaussiana cresce nel tempo, infatti calcolando i momenti della distribuzione si trova $<x(t)>=x_0$, $<(x(t)-x_0)^2>=Dt$.
				Se la topologia del sistema fosse una circonferenza (e non una retta), si avrebbe un rilassamento esponenziale a una situazione stazionaria.
				\\Definito un intervallo $-L,L$ sulla retta, la probabilità che il punto vi sca dopo un tempo $t$ è data da:
				\begin{equation}
					P(\left\lvert x\right\rvert >L)=1-\int_{-L}^{L}\frac{1}{\sqrt{2\pi Dt}}e^{-\frac{x^2}{2Dt}}dx
				\end{equation}
				Si può facilmente notare come raddoppiando la distanza $L$ il tempo $t$ quadruplichi.
			\subsection{Random Walk 2D}
				Volendo espandere il modello di random walk ad uno spazio 2D si nota subito come, essendo ogni asse indipendente dall'altro, si possa semplicemente comporre due gaussiane:\\
				\begin{equation}
					(x,y)\simeq\frac{1}{2\pi\Delta t}e^{-\frac{x^2+y^2}{2\Delta t}}=\rho(x,y,t)
				\end{equation}
				Dove la diffusione segue la definizione precedente ed è la stessa in tutte le direzioni.
				La funzione $\rho(x,y,t)$ rappresnta di fatto la probabilità che la il soggetto in analisi si trovi in un volume $\Delta x\Delta y$.
				Si può riscrivere la relazione precedente in coorfinate polari ottenendo:
				\begin{equation}
					\rho(r,\theta,t)=\frac{r}{2\pi\Delta t}e^{-\frac{r^2}{2\Delta t}}
				\end{equation}
				studiando più semplicemente l'allontanamento dall'origine.
				In particolare, l'allontanamento medio risulta:
				\begin{equation}
					<r>=\int_0^\infty\rho(r,\theta,t)rdr=\sqrt{\frac{\pi}{2}\Delta t}
				\end{equation}
				e la densità diminuisce quindi esponenzialmente.
			\subsection{Random Walk non omogenea}
			Si consideri ora una random walk 1D con probabilità non uniforme in un reticolo di passo $\Delta x$.
			Sia $\epsilon$ un parametro e si definiscano le probabilità:
			\begin{equation}
				\begin{cases}
					p_{++}=p_{--}=\frac{1}{4}(1+\epsilon x)\quad x\geq 0\quad\Rightarrow x\rightarrow x\pm 2\Delta x\\
					p_+=p_-=\frac{1}{4}(1-\epsilon x)\quad x<0\quad\Rightarrow x\rightarrow x\pm \Delta x
				\end{cases}
			\end{equation}
			Si può verificare facilmente come le probabilità siano ben definite.
			Il sistema tende a muoversi più velocemente nel verso positivo delle \textit{x} e più lentamente nel verso opposto, assomigliando a una scatola con aria a diversa temperatura: vi è quindi un equilibrio locale (ogni nodo è identico).
			Si può osservare come:
			\begin{equation}
				\begin{split}
					<\Delta x>&=0\\
					<\Delta x^2>&=(4\Delta x^2)(p_{++}+p_{--})+\Delta x^2(p_++p_-)=\left(\frac{5}{2}+\frac{3}{2}\epsilon x\right)\Delta x^2
				\end{split}
			\end{equation}
			Ogni passo ho un \textit{enemble} differente, quindi lo spazio non è omogeneo.
			Ponendo $T(x)=<\Delta x^2>$ come funzione corrispondente alla temperatura fisica, si ottiene un gradiente costante:
			\begin{equation}
				\frac{dT}{dx}=\frac{3}{2}\epsilon\Delta x^2
			\end{equation}
			Questo gradiente si ritrova spesso in natura, ad esempio i batteri variano la velocità di movimento (casuale) dei loro flagelli seguendo un gradiente di cibo.
			Per essere apprezzabile la variazione di temperatura deve essere tale che $\Delta T=\frac{\partial T}{\partial x}\Delta x\propto\Delta x^3$ e in un limite continuo si ottiene:
			\begin{equation}
				\begin{split}
					\frac{\partial p}{\partial t}&=\frac{1}{2}\frac{\partial p}{\partial x}T(x)\frac{\partial p}{\partial x}p(x,t)\\
					\frac{d<x>}{dt}&=\frac{1}{2}\int x\frac{\partial p}{\partial x}T(x)\frac{\partial p}{\partial x}p(x,t)>0\quad \frac{\partial T}{\partial x}>0
				\end{split}
			\end{equation}
			Andando a calcolare media e mediana del sistema si nota come:
			\begin{equation}
				\begin{split}
					\int xp(x,t)dx&>0\\
					-\int_{-L}^0p(x,t)dx&+\int_0^Lp(x,t)dx<0
				\end{split}
			\end{equation}
			In conclusione la maggior parte delle particelle si trova nella zona fredda ($x<0$), come vuole la fisica, ma la media della distribuzione si trova nella zona calda ($x>0$).
			\subsection{Dinamica generica di interazione}
				Consideriamo di avrere $n_{0}$ individui iniziali su una griglia (spazio discretizzato) che si muovono seguendo una Random Walk 2D e soggetti alle seguenti restrizioni:
				\begin{itemize}
					\item se un individuo ha spazio sufficiente, si riproduce in un tempo $\Delta t$, allora si deve avere $\Delta n(t)\propto n(t)$;
					\item se due individui competono per lo stesso spazio, uno dei due soccombe con una certa probabilità $p$, il che implica $\Delta n(t)\propto -n^{2}(t)$;
				\end{itemize}
				Si osservi come il termine $n^{2}(t)$ conti il numero di coppie.
				Definita la scala di tempo $\Delta t$, in un modello continuo si deve avere (teoria del campo medio):
				\begin{equation}
					n(t+\Delta t)=n(t)+\left(an(t)-bn^{2}(t)\right)\Delta t
				\end{equation}
				con $a$ parametro di riproduzione e $\frac{b}{a}$ competizione nella popolazione (dato dall'ambiente).
				Imponendo l'equilibrio
				\begin{equation}
					\dot{n}(t)=an(t)\left(1-\frac{b}{a}n(t)\right)=0
				\end{equation}
				si ottengono i punti critici $n=0$, instabile, e $n=\frac{a}{b}$ stabile.
				La soluzione al sistema è quindi del tipo
				\begin{equation}
					\frac{an_{0}}{\left(a-bn_{0}\right)e^{-at}+bn_{0}}
				\end{equation}
				e la funzione logistica del sistema è
				\begin{equation}
					f(t)=\frac{1-e^{-t}}{1+e^{-t}}=\tanh\frac{t}{2}
				\end{equation}
			\subsection{Catmap}
				Consideriamo un gatto su un toro $\Pi^{2}$ (ciambella) in gradi di muoversi secondo la:
				\begin{equation}
					\left(
					\begin{matrix}
						x_{n} \\
						y_{n} 
					\end{matrix}
					\right)=
					\left(
					\begin{matrix}
						2 & 1\\
						1 & 1 
					\end{matrix}
					\right)
					\left(
					\begin{matrix}
						x_{n-1} \\
						y_{n-1} 
					\end{matrix}
					\right)
				\end{equation}
				Risulta ovvio come
				\begin{equation}
					\det
					\left(
						\begin{matrix}
							2 & 1\\
							1 & 1 
						\end{matrix}
					\right)=1
				\end{equation}
				quindi si conservino le aree.
				Calcolo degli autovalori:
				\begin{equation}
					\det
					\left(
						\begin{matrix}
							2-\lambda & 1\\
							1 & 1-\lambda
						\end{matrix}
					\right)=\lambda^{2}-3\lambda+1=0
				\end{equation}
				e si ottengono
				\begin{equation}
					\begin{cases}
						\lambda_{\pm}=\frac{3\pm\sqrt{5}}{2}\\
						\lambda_{+}\lambda_{-}=1
					\end{cases}
				\end{equation}
				Il sistema dilata densamente lungo la direzione $v_{+}$ dell'autovettore $\lambda_{+}>1$.
				Dato un vettore iniziale $x_{0}$, $(x_{0}\cdot v_{t})\lambda_{t}^{n} \Rightarrow \ln\lambda_{t}$ è l'esponenziale di Ljapunov.
				Problema: data una distribuzione di punti $\rho_{0}$, cosa succede a $\rho_{0}(T^{n}x)$?
				\\Per definizione, data una distribuzione $\rho(x)$, questa deve essere normalizzata $\int_{\Pi^{2}}\rho(x)dx=1$.
				L'equazione di continuità permette di imporre la conservazione del numero di particelle:
				\begin{equation}
					\rho(x,n)=\rho_{0}\left(T^{-n}x\right)\left\lvert\frac{\partial T^{-n}}{\partial x}\right\rvert 
				\end{equation}
				in cui si riconosce $\left\lvert\frac{\partial T^{-n}}{\partial x}\right\rvert=
				\det
				\left(
					\begin{matrix}
						2 & 1\\
						1 & 1 
					\end{matrix}
				\right)=1$, quindi $\rho_{0}\left(T^{n}x\right)$ evolve in una distribuzione di particelle.
				Si può ora constatare che, se $I(x)$ è un osservabile del sistema, vale la relazione:
				\begin{equation}
					<I>(n)=\int I(x)\rho(x,n)dx
				\end{equation}
				La teoria suggerisce l'esistenza di una distribuzione invariante $\rho_{s}\left(T^{-n}x\right)=\rho_{s}$.
				Sia ora $\chi_{A}(x)$ la funzione caratteristica del dell'insieme $A$, e $\rho_{0}(y)=\frac{\chi_{A}(y)}{m(A)}$, $I(x)=\chi_{B}(x)$.
				L'integrale precedente diviene:
				\begin{equation}
					\begin{split}
						<I>(n)=\int\chi_{B}(x)\frac{\chi_{A}T^{-n}x}{m(A)}dx&=\int_{B}\frac{\chi_{A}T^{-n}x}{m(A)}dx=\\
						=\frac{1}{m(A)}\int_{T^{B}}\chi_{A}(y)dy&=\frac{1}{m(A)}m(A)m(B)=m(B)\\
						m(B)&=\int\chi_{B}(x)\rho_{s}(x)dx
					\end{split}
				\end{equation}
				e si è così dimostrato il teorema \ref{theorem:poincare}.
			\subsection{Modello economico}
				Si vuole ora costruire un primo modello legato alla realtà simulando, per quanto grossolanamente, l'economia globale.\\
				Supponiamo di avere \textit{M} individui con \textit{n} soldi ciascuno, che si muovono su una griglia secondo una Random Walk 2D.
				Ogni qualvolta due individui si trovino sulla stessa cella questi si scambiano 1 soldo con probabilità $p=\frac{1}{2}$.\\
				\textbf{Caso limite}: se si incontra un povero ($n=0$), si gioca lo stesso (gioco scorretto) per permettere a tutti di uscire dalla povertà.
				Il sistema ha quindi i seguenti limiti:
				\begin{equation}
					\begin{cases}
						\sum_kn_k=N\\
						n_k\geq 0
					\end{cases}
				\end{equation}
				con \textit{N} costante, quindi non si ha creazione/distruzione di denaro.
				La probabilità di trovare un individuo con n soldi è:
				\begin{equation}
					p(n)=\frac{\binom{M+N-2-n}{M-2}}{\binom{M+N-1}{N-1}}
				\end{equation}
				e, ponendo $\overline{n}=\frac{N}{M}$, si può calcolare:
				\begin{equation}
					\lim_{M\to\infty}\frac{1}{\overline{n}}\left( 1-\frac{n}{M}\right)^M=\frac{1}{\overline{n}}e^{-\frac{n}{\bar{n}}}
				\end{equation}
				quindi la probabilità decresce esponenzialmente.\\
				Il modello prevede quindi:
				\begin{itemize}
					\item molti poveri e pochi ricchi (ma praticamente nessun super-ricco)
					\item esiste un tempo in cui un povero diventa ricco (e viceversa)
					\item simile alla distribuzione di energia di Maxwell-Boltzmann
					\item se chi è ricco pagasse di più si otterrebbe una curva a campana
				\end{itemize}
				Tuttavia osservando i dati sperimentali si nota una discrepanza: nella realtà la probabilità sembra seguire una legge a potenza piuttosto che esponenziale.
			\subsection{Modello economico evoluto}
				Per adattare il modello precedente alla realtà si introduce una microdinamica sugli scambi di denaro.\\
				Sia $\pi_\pm$ la probabilità di guadagnare $\pm 1$ soldi se un soggetto ne possiede \textit{n}. Il sistema possiede una \textit{struttura di catena}:
				\begin{definition}
					Struttura di catena.\\
					Un modello ha struttura di catena quando il flusso in una direzione implica un secondo flusso nella direzione opposta.
				\end{definition}
				A causa di questa struttura, all'equilibrio si deve avere:
				\begin{equation}
					\pi_+(n-1)p(n-1)+\pi_-(n+1)p(n+1)=\pi_+(n)p(n)+\pi_-(n)p(n)
				\end{equation}
				e in particolare è verificato il \textit{bilancio dettagliato}:
				\begin{equation}
					\pi_+(n-1)p(n-1)=\pi_-(n)p(n)\quad \forall n\geq 1
				\end{equation}
				Normalizzata la distribuzione è possibile iterare il tutto:
				\begin{equation}
					p(n)=\prod_{k=1}^n\frac{\pi_+(k-1)}{1pi_-(k)}p(0)
				\end{equation}
				Riscrivendo un maniera più comoda il bilancio dettagliato, si può poi procedere:
				\begin{equation}
					\pi_+(n-\frac{1}{2})p(n-\frac{1}{2})=\pi_-(n+\frac{1}{2})p(n+\frac{1}{2})
				\end{equation}
				\begin{equation}
					\begin{split}
						[\pi_+(n)-\pi_-(n)]p(n)-\frac{1}{2}\frac{\partial}{\partial n}[\pi_+(n)-\pi_-(n)]p(n)\simeq 0\\
						ap(n)+\frac{\partial}{\partial n}(bn)p(n)\simeq 0
					\end{split}
				\end{equation}
				Si possono notare ora le seguenti dipendenze, introducendo la coppia di parametri costanti \textit{(a, b)}:
				\begin{equation}
					\begin{cases}
						\pi_+(n-1)-\pi_-(n)\simeq a\\
						\pi_+(n)\simeq bn-\frac{a}{2}\\
						\pi_-(n)\simeq bn+\frac{a}{2}
					\end{cases}
				\end{equation}
				Cercando ora l'andamento di $p(n)$:
				\begin{equation}
					\begin{split}
						p(n)-p(n-1)&=\left(\frac{bn-\frac{a}{2}}{bn+\frac{a}{2}}-1\right)p(n-1)\\
						\frac{dp}{dn}&=-\frac{a}{bn}p(n-1)\\
						\Rightarrow\lim_{n\to\infty}p(n)&\propto n^{-\frac{a}{b}}
					\end{split}
				\end{equation}
				si ottiene esattamente l'andamento a potenza ricercato.
			\subsection{La rovina di un giocatore}
				Si consideri un giocatore d'azzardo con a disposizione un capitale \textit{k} e che vuole arrivare ad un capitale \textit{M}.
				Il gioco finisce ai ``bordi'' (barriera assorbente) per $k=0$ (giocatore rovinato) o per $k=M$ (giocatore felice).
				Siano $p$ la probabilità di guadagnare, $q=1-p$ la probabilità di perdere, $P_M(k)$ la probabilità di arrivare al capitale \textit{M} partendo da \textit{k}.
				Come nel modello economico evoluto si ha:
				\begin{equation}
					P_M(k)=pP_M(k+1)+qP_M(k-1)
				\end{equation}
				con i vincoli
				\begin{equation}
					\begin{cases}
						P_M(0)=0\\
						P_M(M)=1
					\end{cases}
				\end{equation}
				Ragionando per induzione si ottiene:
				\begin{equation}
					P_M(k+1)-P_M(k)=\frac{q}{p}\left[P_M(k)-P_M(k-1)\right]=\left(\frac{q}{p}\right)^kP_M(1)
				\end{equation}
				\begin{equation}
					P_M(k)=\frac{1-\left(\frac{q}{p}\right)^k}{1-\left(\frac{q}{p}\right)^M}
				\end{equation}
				Ponendo ora $p>q$,
				\begin{equation}
					P_\infty(k)=1-\left(\frac{q}{p}\right)^k
				\end{equation}
				In particolare, considerando un gioco equo, si può notare come $P_M(k)=\frac{k}{M}$ e quindi:
				\begin{itemize}
					\item il gioco è alla pari solo se $k\simeq M$
					\item la probabilità di vincita aumenta all'aumentare del proprio capitale rispetto a quello avversario
					\item contro un casinò ($M\to\infty$) la probabilità di vincita è evidentemente nulla anche in caso di gioco equo (assunzione oltretutto inverosimile)
				\end{itemize}
	
	\chapter{Entropia e Informazione} %CAPITOLO 2
		\section{Distribuzioni}
		Vediamo ora una serie di distribuzioni e teoremi ad esse legati che ci aiuteranno nell'analisi dei sistemi.
		\begin{definition}\hfill
			\begin{itemize}
				\item Gaussiana\\	$\rho(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$
				\item Esponenziale\\	$\rho(x)=\frac{1}{k}e^{-\frac{x}{k}}$
				\item Potenza\\		$\rho(x)\propto\frac{1}{x^a}$, con $a>0$
			\end{itemize}
		\end{definition}
		\begin{definition}
			Momenti di una distribuzione:\\
			$<x^k>=\int_{-\infty}^{+\infty}x^k\rho(x)dx$
		\end{definition}
		\begin{theorem}
			Invarianza di scala:\\
			se $\rho(x)\propto\frac{1}{x^a}$ allora posto $y=\lambda x$ si ha $\rho(y)=\frac{\lambda^a}{x^a}\propto\frac{1}{y^a}$
		\end{theorem}
		\begin{theorem}
			Limite centrale:\\
			Siano ${x_k}$ variabili casuali indipendenti, allora:\\
			$\lim_{N\to\infty}z=\frac{1}{\sqrt{N}}\sum_{k=1}^{N}x_k=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{z^2}{2\sigma^2}}$
		\end{theorem}
		
		\section{Probabilità}
			Data una distribuzione di probabilità $\rho(x)$ normalizzata è possibule procedere con le seguenti definizioni:
			\begin{definition} Probabilità:\\
				$p(x\in[a,b])=\int_{a}^{b}\rho(x)dx$
			\end{definition}
			\begin{definition} Probabilità cumulata:\\
				$p(x\leq a)=\int_{-\infty}^{a}\rho(x)dx$
			\end{definition}
			\begin{definition}
				Una variabile $x$ a valori discreti $\{x_0,x_1,...\}$ è detta variabile di CODING
			\end{definition}
			Considerando una sequenza (\textit{codifica}) $\{x_k\}_1^N$ si può assumere $P(\{x_k\})=p(x_1)...p(x_N)$.
			Una codifica è detta \textbf{ottimale} se può descrivere in maniera univoca un'orbita.
			\begin{definition}
				$-\ln(x)$ informazione portata dal carattere $x$
			\end{definition}
			\begin{definition}
				Probabilità stazionaria\\
				La probabilità stazionaria è il numero di volte che questo evento accade in una sequenza.
			\end{definition}
			\begin{definition}
				$S=-\sum_kp(x_k)\ln(p(x_k))$ entropia di informazione (informazione media portata dale variabili $x_k$)
			\end{definition}
			Si nota subito come più un valore della variabile di coding è probabile, minor informazione questo porti.
			Informaticamente, la misura è circa il numero di bit necessari per memorizzare la sequenza.
			Non bisogna confondere entropia con informazione: la variabile deve avere un significato!
			\begin{theorem}
				legge dei grandi numeri\\
				Siano A e B due eventi distinti (osservati N volte), allora si ha che\\
				$\lim_{N\to\infty}\frac{p(AB)}{p(A)}=p(B/A)$
			\end{theorem}

			\subsection{Matrice stocastica}
				Per capire la sequenza bisogna conoscerne la \textit{memoria}, ossia tutte le dipendenze di un evento dagli altri.
				L'\textit{irreversibilità} di un evento si ha quando la coppia di eventi $AB$ è diversa dalla coppia di eventi $BA$.
				\begin{definition}
					$p_{ij}=p(x_j/x_i)$ matrice stocastica
				\end{definition}
				La matrice stocastica ha per definizione le seguenti proprietà:
				\begin{itemize}
					\item $0\leq p_{ij}\leq 1$
					\item $\sum_jp_{ij}=1$
				\end{itemize}
				Questa matrice è molto importante, essento intrinsecamente legata alla probabilità condizionata, ed è alla base di ogni problema di trasporto.
				Si consideri ora una sequenza infinita e sia $p_i$ la probabilità di avere l'elemento $x_i$ in quella posizione.
				Qual è la probabilità $p_j$ di avere l'elemento successivo?
				Sia \textit{n} il numero di passi per arrivare in posizione \textit{i}, allora:
				\begin{equation}
					p_j^{n+1}=\sum_ip_{ij}p_j^n
				\end{equation}
				Risulta quindi utile il seguente teorema:
				\begin{theorem}
					Esiste un autovettore con autovalore $\lambda_0=1$, ossia\\
					$p_j^s=\sum_ip_{ij}p_j^s$
				\end{theorem}
				Corollari:
				\begin{itemize}
					\item è un vettore stazionario situato nel primo quadrante
					\item gli iperpiani sono invarianti per $p_{ij}$
					\item $\lambda_i<1\quad\forall i\neq 0$
					\item $p_j^{n+1}=\sum_ip_{ij}p_j^n=1\Leftrightarrow\sum_ip_i^n=1$
				\end{itemize}
		
		\section{Teoria di Markov}
			A questo punto si può calcolare come cambi l'entropia di informazione di una catena aggiungendo un carattere.
			\begin{definition}
				Proprietà di Markov (di tempo presente)\\
				$P(\{x_1,...,x_{n+1}\})=P(x_{n+1}/Px_n)P(\{x_1,...,x_{n}\})$
			\end{definition}
			Si può quindi scrivere l'entropia dell'(N+1)esimo passo come:
			\begin{equation}
				S_{N+1}=S_N-\sum_{ij}p_j^sp_{ij}\ln p_j
			\end{equation}
			Nei linguaggi l'aggiunta di un carattere non cambia di molto l'entropia (per fortuna, altrimenti sarebbe molto difficile parlarsi).
			Questa entropia fornisce tuttavia un'importante risultato sulla reversibilità del processo:
			se invertendo il tempo non ho differenza di entropia, allora il processo è \textit{reversibile}, altrimenti no.
			Le \textbf{fluttuazioni} di un sistema \textbf{all'equilibrio} sono sempre un processo \textbf{reversibile}, infatti osservando tale sistema non si riesce a distinguere tra passato e futuro.
			Come esempio per giustificare la precedente affermazione si può prendere un pendolo fisico in assenza di attriti/forse esterne, oppure un \textit{moto browniano}.\\
			In conclusione, la teoria dell'informazione è applicabile quasi in ogni ambito.
			Sono stati effettuati studi sui linguaggi, premiando finlandese e tedesco come lingue più entropiche, e studi sulla musica, che vedono Bach meno entropico di Hindemith.
		
		\section{Esempi}
			\subsection{Utilizzo della misura invariante}
				Sia $x_{n}=2^{n}$ un numero, con $n \geq 1$.
				Qual è la probabilità che esso abbia un $7$ come prima cifra?
				\\Supponendo $2^{n}=7.\cdots\times 10^{k}$, allora $\log{2^{n}}=\log{7.\cdots}+k$.
				Si consideri ora la dinamica
				\begin{equation}
					y_{n+1}=y_{n}+\log2\mod1
					\label{equation:cifre}
				\end{equation}
				che rappresenta sostanzialmente una traslazione nell'intervallo $[0,1]$.
				In questo caso l'esponente di Ljapunov è nullo in quanto non vi è espansione.
				Iterando la \ref{equation:cifre} si ottiene
				\begin{equation}
					y_{n}=y_{0}+n\log2\mod1
				\end{equation}
				e la misura invariante risulta quindi una distribuzione uniforme nell'intervallo $[0,1]$.
				Da qui la probabilità $\lim_{n\to\infty}P(7)=\log8-\log7$.
			\subsection{Entropia di una mano di carte}
				Supponiamo di possedere un mazzo di $N$ carte differenti e di pescare da esso $k$ carte.
				Per calcolare l'entropia di informazione associata alla mano pescata, bisogna innanzitutto calcolare la probabilità di una mano singola.
				Le combinazioni di $k$ carte di un mazzo di $N$ carte sono date dal coefficiente binomiale:
				\begin{equation}
					C=\binom{N}{k}=\frac{N!}{k!(N-k)!}
				\end{equation}
				Assumendo che il mazzo non sia truccato, quindi che ogni estrazione sia equiprobabile, la probabilità di ogni singola mano è $p_{i}=\frac{1}{C}$.
				L'entropia di informazione (o di Shannon) associata ad essa è quindi 
				\begin{equation}
					S=-k_{S}\sum_{i=1}^{C}p_{i}\ln{p_{i}}=-k_{S}C\left(\frac{1}{C}\ln{\frac{1}{C}}\right)=k_{S}\ln{\frac{N!}{k!(N-k)!}}
				\end{equation}
				con $k_{S}=\frac{1}{\ln2}$ costante di Shannon.
			\subsection{Broken Stick Model/Modello di Markov}
				Si consideri un segmento di lunghezza unitaria nel quale viene inserito casualmente un punto $x_1\in[0,1]$ secondo una distribuzione uniforme.
				Si scarti ora il segmeno $[0,x_1]$ e si iteri il processo per \textit{N} volte: si tratta di un processo ricorsivo con memoria del passato.
				Essendo la distribuzione di probabilità uniforme risulta ovvio come $<x>=\frac{1}{2}$ quindi è possibile riscalare il tutto con una variabile $y\rightarrow\frac{y}{2}$
				Definita la densità $\rho$ del sistema si può scrivere:
				\begin{equation}
					\begin{split}
						\rho_{N+1}\left(\frac{y}{2}\right)\frac{dy}{2}&=\rho_N(y)dy\\
						\Rightarrow\lim_{N\to\infty}\rho_N(y)&\propto\frac{1}{y}
					\end{split}
				\end{equation}
				Il risultato è una legge a potenza con $\alpha=-1$, quindi \textit{non normalizzabile} in quanto l'integrale diverge.
				Il sistema ha un effetto di memoria assoluta: una volta tagliato il segmento non è possibile riattaccarlo.
				Se il segmento non venisse tagliato si otterrebbe un andamento a potenza con $\alpha\geq 1$ e risulterebbe pertanto normalizzabile.
				Un'utile applicazione dei modelli di Markov si trova nel linguaggio (verbi) e in biologia (DNA).
			\subsection{Penney's game}
				Si prenda una moneta e la si lanci all'infinito.
				Si vuole scommettere con un'altra persona su una terna di uscite consecutive dai lanci e ci si chiede come si possa vincere più facilmente.
				Analizzando attentamente il problema si può notare come l'uscita delle sequenze non sia casuale ma segua un percorso ben preciso: l'unica sequenza casuale è quella data dalle prime tre uscite.
							
				\begin{figure}
					\centering
					\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        
					\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
					%uncomment if require: \path (0,180); %set diagram left start at 0, and has height of 180

					%Straight Lines [id:da6422687951145654] 
					\draw    (44,65) -- (85,32) -- (90,28) ;
					\draw [shift={(91,27)}, rotate = 501.04] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da7705936405819056] 
					\draw    (94,137) -- (40.53,92.28) ;
					\draw [shift={(39,91)}, rotate = 399.90999999999997] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da6670914365776015] 
					\draw    (120,90) -- (120,121) ;
					\draw [shift={(120,123)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da5676959026170221] 
					\draw    (119,32) -- (119,63) ;
					\draw [shift={(119,65)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da6639824453006449] 
					\draw    (137,22) -- (172,22) ;
					\draw [shift={(174,22)}, rotate = 180] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da07868476619961107] 
					\draw    (179,138) -- (140,138) ;
					\draw [shift={(138,138)}, rotate = 360] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da2178688499902217] 
					\draw    (178,77) -- (139,77) ;
					\draw [shift={(137,77)}, rotate = 360] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da6042868291237622] 
					\draw    (139,84) -- (175,84) ;
					\draw [shift={(177,84)}, rotate = 180] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da3451851868864586] 
					\draw    (218,21) -- (274.42,64.77) ;
					\draw [shift={(276,66)}, rotate = 217.81] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da5761550996457687] 
					\draw    (275,95) -- (223.51,139.69) ;
					\draw [shift={(222,141)}, rotate = 319.03999999999996] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da9885549593906195] 
					\draw    (197,128) -- (197,89) ;
					\draw [shift={(197,87)}, rotate = 450] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da6638039461895064] 
					\draw    (198,70) -- (198,31) ;
					\draw [shift={(198,29)}, rotate = 450] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Curve Lines [id:da8915331259906252] 
					\draw    (100,130) .. controls (60.42,98.3) and (61.96,64.68) .. (100.81,34.9) ;
					\draw [shift={(102,34)}, rotate = 503.13] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Curve Lines [id:da07525012510942974] 
					\draw    (213,29) .. controls (259.53,59.69) and (261.96,88.42) .. (219.31,127.8) ;
					\draw [shift={(218,129)}, rotate = 317.73] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;

					% Text Node
					\draw (20,70) node [anchor=north west][inner sep=0.75pt]   [align=left] {HHH};
					% Text Node
					\draw (100,15) node [anchor=north west][inner sep=0.75pt]   [align=left] {HHT};
					% Text Node
					\draw (100,70) node [anchor=north west][inner sep=0.75pt]   [align=left] {HTH};
					% Text Node
					\draw (100,130) node [anchor=north west][inner sep=0.75pt]   [align=left] {THH};
					% Text Node
					\draw (180,70) node [anchor=north west][inner sep=0.75pt]   [align=left] {THT};
					% Text Node
					\draw (260,70) node [anchor=north west][inner sep=0.75pt]   [align=left] {TTT};
					% Text Node
					\draw (180,15) node [anchor=north west][inner sep=0.75pt]   [align=left] {HTT};
					% Text Node
					\draw (180,130) node [anchor=north west][inner sep=0.75pt]   [align=left] {TTH};

					\end{tikzpicture}
					\caption{Schema del gioco di Penney}
					\label{Penney's scheme}
				\end{figure}
				In questo modo risulta abbastanza semplice fregare l' avversario: facendolo scegliere per primo, è sempre possibile scegliere una sequenza più probabile della sua.\\
				Eseguendo i calcoli si nota subito come la probabilità stazionaria del sistema sia data da $\left(\frac{1}{2}\right)^3=\frac{1}{8}=12.5\%$.
				Scegliendo per secondi si vince sempre a meno che la sequenza dell'avversario non esca dai primi tre lanci, quindi eseguendo i calcoli sulle probabilità si ottiene la seguente tabella:
				\begin{center}
					\begin{tabular}{ |c|c|c|c| } 
						\hline
						1st player's choice& 2nd player's choice & 2nd player's winning chance\\
						\hline
						\emph{HH}H & \textbf{T}\emph{HH} & 87.5\% \\
						\emph{HH}T & \textbf{T}\emph{HH} & 75.0\% \\
						\emph{HT}H & \textbf{H}\emph{HT} & 66.7\% \\
						\emph{HT}T & \textbf{H}\emph{HT} & 66.7\% \\
						\emph{TH}H & \textbf{T}\emph{TH} & 66.7\% \\
						\emph{TH}T & \textbf{T}\emph{TH} & 66.7\% \\
						\emph{TT}H & \textbf{H}\emph{TT} & 75.0\% \\
						\emph{TT}T & \textbf{H}\emph{TT} & 87.5\% \\
						\hline
					\end{tabular}
				\end{center}

	\chapter{Modelli di trasporto} %CAPITOLO 3
		\section{Teoria}
			Consideriamo due punti ($A$ e $B$) di un generico spazio e colleghiamoli con un canale immaginario, facendo riferimento alla Fig.1, possiamo definire il flusso $\Phi_{A \rightarrow B}$ di una quantità fisica trasportata nell'unità di tempo tra i due punti.
			\begin{figure}[ht!]
					\centering
					\begin{tikzpicture}
					\Vertex[label=$A$, color=white]{A}
					\Vertex[label=$B$,color=white,x=2.5,y=0]{B}
					\Edge[Direct, lw=0.5pt, label=$\Phi_{A \rightarrow B}$](A)(B)
				\end{tikzpicture}
					\caption{}
			\end{figure}
			Definiamo $V_{A/B}$ una certa proprietà del nodo $A/B$, questa proprietà ne definisce lo stato. Possiamo quindi scrivere una sorta di legge di Ohm per la situazione descritta 
			\begin{equation}
					\Phi_{A \rightarrow B} \ R = V_A - V_B
			\end{equation} dove $R$ è una proprietà del link (ad es. la portanza di una strada ma anche la probabilità di transizione).
			Osserviamo che è di notevole importanza la dimensione del link ($L$) in quanto se attraversiamo il link abbiamo un flusso $\Phi$, di conseguenza la capacità del sistema di trasporto richiede $\Phi L$ di “veicoli".			
			\begin{figure}[ht!]
					\centering
					\begin{tikzpicture}
						\Vertex[label=$A$, color=white]{A}
						\Vertex[label=$B$,color=white,x=1,y=1]{B}
						\Vertex[label=$C$,color=white,x=-1,y=1]{C}
						\Vertex[label=$D$,color=white,x=0,y=1]{D}
						\Vertex[label=$S$,color=white,x=0,y=-1]{S}
						\Edge[Direct, lw=0.5pt](A)(B)
						\Edge[Direct, lw=0.5pt](A)(C)
						\Edge[Direct, lw=0.5pt](A)(D)
						\Edge[Direct, lw=0.5pt](S)(A)
					\end{tikzpicture}
					\caption{}
			\end{figure}
		
		\section{Esempi}

		
	
	
	\chapter{Teoria del controllo} %CAPITOLO 4
		\section{Approccio generale}
			La \emph{teoria del controllo} è quella branca della fisica che studia come controllare i sistemi dinamici.
			L'obiettivo principale è quello di creare un \emph{controllo}, ossia un modello/algoritmo, in grado di portare un sistema dinamico in un determinato stato dato uno stato iniziale (in input).
			\begin{definition}
				Il modello è detto ottimale quando si è raggiunto un buon livello di stabilità, minimizzando i riratdi e gli errori.
			\end{definition}
			Il dispositivo che gestisce il sistema dinamico è detto \emph{controllore} e va selezionato accuratamente in base alle richieste del sistema da gestire.
			Formalmente il controllo viene immesso nel sistema attraverso una forzante che, aggiunta alla lagrangiana, permette lo studio e l'ottimizzazione del problema.
			Per maggiori informazioni sulla meccanica analitica è possibile consultare gli appunti delle lezioni al link \url{https://github.com/Grufoony/Fisica_UNIBO/blob/main/Appunti_meccanica_analitica.pdf}.

		\section{Esempi}
			\subsection{Pendolo rovesciato}
				L'esempio più classico di sistema controllabile è dato dal pendolo rovesciato.
				\begin{figure}
					\centering
						\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        
					\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
						%uncomment if require: \path (0,300); %set diagram left start at 0, and has height of 300
		
						%Shape: Axis 2D [id:dp3368840244616125] 
						\draw  (85,261) -- (358,261)(112.3,54) -- (112.3,284) (351,256) -- (358,261) -- (351,266) (107.3,61) -- (112.3,54) -- (117.3,61)  ;
						%Straight Lines [id:da9817096320288043] 
						\draw    (301,111) -- (210,261) ;
						%Straight Lines [id:da06758975743465334] 
						\draw  [dash pattern={on 4.5pt off 4.5pt}]  (210,109) -- (210,261) ;
						%Straight Lines [id:da2034168201391482] 
						\draw    (210,209) -- (231.29,221.96) ;
						\draw [shift={(233,223)}, rotate = 211.33] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
						%Shape: Circle [id:dp9770248165887236] 
						\draw  [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ,fill opacity=1 ] (204.5,261) .. controls (204.5,257.96) and (206.96,255.5) .. (210,255.5) .. controls (213.04,255.5) and (215.5,257.96) .. (215.5,261) .. controls (215.5,264.04) and (213.04,266.5) .. (210,266.5) .. controls (206.96,266.5) and (204.5,264.04) .. (204.5,261) -- cycle ;
						%Shape: Circle [id:dp8368022401757067] 
						\draw  [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ,fill opacity=1 ] (295.5,111) .. controls (295.5,107.96) and (297.96,105.5) .. (301,105.5) .. controls (304.04,105.5) and (306.5,107.96) .. (306.5,111) .. controls (306.5,114.04) and (304.04,116.5) .. (301,116.5) .. controls (297.96,116.5) and (295.5,114.04) .. (295.5,111) -- cycle ;
		
						% Text Node
						\draw (122,127) node [anchor=north west][inner sep=0.75pt]   [align=left] {$ $};
						% Text Node
						\draw (222,190) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle \theta $};
						% Text Node
						\draw (201,268) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle x_{C}$};
						% Text Node
						\draw (308,88) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle x_{O}$};
						\end{tikzpicture}
					\caption{Pendolo rovesciato}
					\label{figure:pendolo}
				\end{figure}
				Siano $x_{C}(t)$ la coordinata del controllore, $x_{O}(t)$ la coordinata del pendolo di lunghezza $l$ e $\theta$ l'angolo formato da esso con la verticale.
				Utilizzando la meccanica lagrangiana:
				\begin{equation}
					\begin{cases}
						x_{O}=x_{C}+l\sin\theta\\
						y_{O}=l\cos\theta
					\end{cases}
				\end{equation}
				\begin{equation}
					\begin{cases}
						\dot{x}_O=\dot{x}_{C}+l\dot{\theta}\cos\theta\\
						\dot{y}_{O}=l\dot{\theta}\sin\theta
					\end{cases}
				\end{equation}
				La lagrangiana del sistema si può scrivere come:
				\begin{equation}
					\mathcal{L}=\frac{m}{2}\left( \left( \dot{x}_{C}+l\dot{\theta}\cos\theta \right)^2 + l^2\dot{\theta}^2\sin^2\theta \right) - mgl\cos\theta \simeq \frac{m}{2}\left( l^2\dot{\theta}^2 + 2\dot{x}_{C}l\dot{\theta}\cos\theta \right) - mgl\cos\theta
				\end{equation}
				alle piccole oscillazioni ($\theta\simeq 0$ e $mgl\cos\theta\simeq -mgl\frac{\theta^2}{2}$):
				\begin{equation}
					\mathcal{L}_{PO}=\frac{m}{2}\left( l^2\dot{\theta}^2 + 2\dot{x}_{C}l\dot{\theta} \right) + mgl\frac{\theta^2}{2}
				\end{equation}
				L'equazione del moto risulta infine:
				\begin{equation}
					\ddot{\theta}=\frac{g}{l}\theta - \frac{\ddot{x}_C}{l}
				\end{equation}
				Riconosciuta la forzante, per semplicità si pone $\ddot{x}_C=\pm a(t)$ costante.
				La soluzione non è omogenea:
				\begin{equation}
					\theta(t)=\left( \theta_{0} -\frac{a(t)}{g} \right)\cosh\omega t + \frac{\dot{\theta}_0}{\omega}\sinh\omega t +\frac{a(t)}{g}
				\end{equation}
				Assumendo ora $\theta_0\simeq 0$ e $\dot{\theta}_0\neq 0$ e che il pendolo si stabilizzi in un tempo $T$ si ha la soluzione stabile:
				\begin{equation}
					\theta(T)=C\cosh\omega T + C\sinh\omega T \simeq Ce^{-\omega T}
				\end{equation}
				Si può ora ricavare la condizione richiesta:
				\begin{equation}
					C=\theta(T)=-\frac{\dot{\theta}(T)}{\omega}
				\end{equation}
				Andando a imporla si ottiene:
				\begin{equation}
					-\frac{a}{g}\cosh\omega T + \frac{\dot{\theta}(T)}{\omega}\sinh\omega T + \frac{a}{g} = \frac{a}{g}\sinh\omega T - \frac{\dot{\theta}(T)}{\omega}\cosh\omega T
				\end{equation}
				Da cui si può ricavare il periodo di stabilità:
				\begin{equation}
					T=\frac{1}{\omega}\ln\frac{\frac{a}{g}}{\frac{a}{g}-\frac{\dot{\theta}(T)}{\omega}}
				\end{equation}
				Un'osservazione importante riguarda la \emph{condizione critica} del sistema, ove esso non risulta più controllabile, che si ha quando $\dot{\theta}_0=\frac{a\omega}{g}$.
			\subsection{Marriage Model/Modello relazionale}
				Si supponga ora di voler controllare una relazione con un'altra persona, che tipo di relazione conviene studiare?
				La scrittrice Anna Karenina sembra fornire una soluzione al problema, constatando che \emph{tutte le relazioni felici sono uguali ma ogni relazione infelice lo è a modo suo}.
				Sia ora $x(t)$ il grado di felicità nella relazione che, per semplicità si assume positivo ($x(t)\in\mathbb{R}^{+}$) in accordo con l'ipotesi della Karenina.
				L'equazione che descrive la relazione sarà del tipo:
				\begin{equation}
					\dot{x}=-rx(t)+ac(t)
				\end{equation}
				in cui riconosciamo la funzione \emph{costo} $c(t)$ della relazione (ove per costo si intende uscire a cena, fare un regalo, ecc...),il parametro $r$ (quanto la felicità tenda a diminuire) e il parametro $a$ (amplificazione del costo).
				La relazione giungerà al termine una volta arrivati ad un valore minimo della felicità, che verrà denotato come $x_{m}$.
				\\Per rafforzare il modello si introducono ora due potenziali:
				\begin{itemize}
					\item $U(x)$, \emph{utility potential}, il quale indica quanto funziona la coppia.
						Esso deve essere tale che $U'(x)>0$ ma $U''(x)<0$, in quanto troppa felicità tende a saturare la relazione;
					\item $D(c)$, \emph{disutility potential}, il quale tiene conto dello sforzo eseguito.
						Più il costo del mantenimento della relazione aumenta, più essa tende a fallire (non ne vale la pena).
						Ovviamente $D(c)$ deve avere un minimo, dato che esiste uno sforzo considerato accettabile per mantenere la relazione;
				\end{itemize}
				Si può ora definire il funzionale di soddisfazione come:
				\begin{equation}
					W(c)=\int_{0}^{\infty}e^{-\lambda t}\left[U\left(x(t)\right)-D\left(c(t)\right)\right]dt
				\end{equation}
				dove il coefficiente $\lambda^{-1}$ rappresenta la scala di memoria del sistema.
				\\Per ottimizzare il problema si deve avere
				\begin{equation}
					\delta\dot{x}=-r\delta x+a\delta c
				\end{equation}
				e quindi la variazione infinitesima del funzionale
				\begin{equation}
					\delta W(c)=\int_{0}^{\infty}e^{-\lambda t}\left[U'(x)'\delta x-D'(c)\delta c\right]dt=\int_{0}^{\infty}e^{-\lambda t}\left[U'(x)'\delta x-D'(c)\frac{\delta\dot{x}+r\delta x}{a}\right]dt
				\end{equation}
				Integrando per parti:
				\begin{equation}
					-\int e^{-\lambda t}D'(c)\frac{\delta\dot{x}}{a}dt=-\left[ e^{-\lambda t}D'(c)\frac{\delta x}{a} \right]_{0}^{\infty} + \int_{0}^{\infty}\frac{d}{dt}\left[\frac{e^{-\lambda t}D'(c)\delta x}{a}\right]dt
				\end{equation}
				e quindi
				\begin{equation}
					\delta W=\int_{0}^{\infty}\left\{ e^{-\lambda t}U'(x)+\frac{d}{dt}\left[\frac{e^{-\lambda t}D'(c)}{a}\right]-\frac{e^{-\lambda t}D'(c)r}{a} \right\}\delta xdt
				\end{equation}
				Essendo $\delta x$ arbitrario
				\begin{equation}
					D''\left(c(t)\right)\frac{dc}{dt}=(r+\lambda)D'(c)-aU'(x)
				\end{equation}
				\\Si assumano ora, per esempio, i seguenti potenziali
				\begin{equation}
					\begin{cases}
						U(x)=U_{\infty}\left(1-e^{-\alpha x}\right)\\
						D(c)=c\left(c-2c_{0}\right)
					\end{cases}
				\end{equation}
				che forniscono il seguente sistema (equilibrio instabile):
				\begin{equation}
					\begin{cases}
						\dot{x}=-rx+ac\\
						\dot{c}=(r+\lambda)(c-c_{0})-\alpha\frac{e^{-\alpha x}}{2}
					\end{cases}
				\end{equation}
				\begin{figure}[H]
					\centering
					\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        

					\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
					%uncomment if require: \path (0,341); %set diagram left start at 0, and has height of 341

					%Shape: Axis 2D [id:dp3368840244616125] 
					\draw  (57,269.8) -- (396,269.8)(90.9,16) -- (90.9,298) (389,264.8) -- (396,269.8) -- (389,274.8) (85.9,23) -- (90.9,16) -- (95.9,23)  ;
					%Straight Lines [id:da3652200107960064] 
					\draw  [dash pattern={on 0.84pt off 2.51pt}]  (91,40) -- (400,41) ;
					%Straight Lines [id:da5006530252551029] 
					\draw  [dash pattern={on 0.84pt off 2.51pt}]  (120,40) -- (121,271) ;
					%Straight Lines [id:da8026254906595234] 
					\draw    (132,51) -- (230.59,149.59) ;
					\draw [shift={(232,151)}, rotate = 225] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da13202518334193436] 
					\draw    (232,151) -- (329.59,52.42) ;
					\draw [shift={(331,51)}, rotate = 134.71] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da12999604842472334] 
					\draw    (232,151) -- (132.42,249.59) ;
					\draw [shift={(131,251)}, rotate = 315.29] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da6286757540841101] 
					\draw    (329,251) -- (233.39,152.44) ;
					\draw [shift={(232,151)}, rotate = 45.87] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da6186409744974593] 
					\draw  [dash pattern={on 0.84pt off 2.51pt}]  (331,90) -- (331,218) ;
					\draw [shift={(331,220)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da17147537985002903] 
					\draw  [dash pattern={on 0.84pt off 2.51pt}]  (131,219) -- (131.98,92) ;
					\draw [shift={(132,90)}, rotate = 90.44] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Curve Lines [id:da625223071951815] 
					\draw    (132,90) .. controls (191.7,96.97) and (225.66,180.16) .. (132.42,218.43) ;
					\draw [shift={(131,219)}, rotate = 338.2] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Curve Lines [id:da4439025038344766] 
					\draw    (331,220) .. controls (245.43,195.12) and (252.92,96) .. (329.84,90.08) ;
					\draw [shift={(331,90)}, rotate = 176.33] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Curve Lines [id:da7044254609861651] 
					\draw    (170,51) .. controls (170,117.33) and (294.47,110.15) .. (298.9,54.7) ;
					\draw [shift={(299,53)}, rotate = 92.01] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Curve Lines [id:da4584745322280377] 
					\draw    (302,250) .. controls (302,182.34) and (163.4,181.01) .. (161.03,248.97) ;
					\draw [shift={(161,250)}, rotate = 270.83] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;

					% Text Node
					\draw (122,127) node [anchor=north west][inner sep=0.75pt]   [align=left] {$ $};
					% Text Node
					\draw (44,169) node [anchor=north west][inner sep=0.75pt]  [rotate=-270] [align=left] {costo};
					% Text Node
					\draw (203,285) node [anchor=north west][inner sep=0.75pt]   [align=left] {felicità};
					% Text Node
					\draw (47,29) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle c_{m}{}_{a}{}_{x}$};
					% Text Node
					\draw (112,275) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle x_{m}$};
					% Text Node
					\draw (333,73) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle A'$};
					% Text Node
					\draw (338,209) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle A$};
					% Text Node
					\draw (123,223) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle B'$};
					% Text Node
					\draw (126,67) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle B$};
					% Text Node
					\draw (190,139) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle \gamma _{B}$};
					% Text Node
					\draw (245,138) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle \gamma _{A}$};


					\end{tikzpicture}
					\caption{Orbite relazionali.}
					\label{figure:orbite}
				\end{figure}
				Le orbite risultanti sono riportate in Fig.(\ref{figure:orbite}), dove si possono distinguere due strategie:
				\begin{itemize}
					\item STRATEGIA A: si segue un'orbita $\gamma_{A}$ dai punti $A\rightarrow A'$ poi si fa una decrescita discontinua lungo una $c(t)$ da $A'\rightarrow A$.
						Sostanzialmente si spende molto per la relazione (nei termini visti in precedenza) poi, una volta divenuto intollerabile il costo, si fa una bella litigata e si ricomincia il ciclo;
					\item STRATEGIA B: si segue un'orbita $\gamma_{B}$ dai punti $B\rightarrow B'$ poi si fa una crescita discontinua lungo una $c(t)$ da $B'\rightarrow B$.
						In questo caso si lascia andare la relazione senza apportare sufficiente sforzo poi, ad un passo dalla rottura, si rimedia il tutto con un gesto importante (alto costo) per ristabilire l'orbita.
				\end{itemize}
				In entrambi i casi bisogna, tuttavia, prestare parecchia attenzione una volta raggiunti i minimi: se lungo la $\gamma_{A}$ si fa una litigata troppo pesante o lungo la $\gamma_{B}$ si trascura troppo la relazione, si rischia di finire fuori orbita (quindi fuori equilibrio) e far così fallire la relazione (il che è \emph{no buono}, n.d.r.).


	\chapter{Altre applicazioni} %CAPITOLO 5
		\section{Teoria}

		\section{Esempi}


	% \section{Networks e problemi di trasporto}
	% 	\begin{theorem}
	% 		Un grafico random ha un numero esponenziale di LOOP rispetto ai nodi.
	% 	\end{theorem}
	% 	Corollario: si creano delle \textit{correnti}.
		
\end{document}
