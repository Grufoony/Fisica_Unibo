
% Copyright (c) 2022, Grufoony
% All rights reserved.

% THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
% AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
% IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
% DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
% FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
% DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
% SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
% CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
% OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
% OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

\documentclass[12pt, a4paper]{book}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[main=italian]{babel}
\usepackage{bookmark}
\usepackage[a4paper, total={6in, 9in}]{geometry}
\usepackage{hyperref}
\usepackage{amsmath, amsthm, amssymb, amsfonts}
\usepackage{pgfplots}
\usepackage{tikz}
\usepackage{caption}
\usepackage{tikz-network}
\usepackage{float}
\floatplacement{figure}{H}
\pgfplotsset{compat = newest}

\theoremstyle{theorem}
\newtheorem{definition}{Definizione}[section]
\newtheorem{theorem}{Teorema}[section]

\begin{document}
	\begin{titlepage}
		\centering % Center everything on the title page
		\scshape % Use small caps for all text on the title page
		Appunti dal Corso di
		\vspace*{1.5\baselineskip} % White space at the top of the page
		% ===================
		% Title Section
		% ===================
		
		
		
		\rule{13cm}{1.6pt}\vspace*{-\baselineskip}\vspace*{2pt} % Thick horizontal rule
		\rule{13cm}{0.4pt} % Thin horizontal rule
		
		\vspace{0.75\baselineskip} % Whitespace above the title
		% ========== Title ===============
		{ \Huge Introduzione alla Fisica\\
		\vspace{4mm}
		dei Sistemi Complessi \\ }
		% ======================================
		\vspace{0.75\baselineskip} % Whitespace below the title
		\rule{13cm}{0.4pt}\vspace*{-\baselineskip}\vspace{3.2pt} % Thin horizontal rule
		\rule{13cm}{1.6pt} % Thick horizontal rule
		
		\vspace{1.75\baselineskip} % Whitespace after the title block
		% =================
		% Information
		% =================
		{}
		Berselli Gregorio \quad Lanzi Samuele\\
		Barbieri Matteo \quad Farnè Gabriele\\
		\url{https://github.com/Grufoony/Fisica_UNIBO}
		\vfill
	\end{titlepage}
	\tableofcontents
	\chapter{Introduzione} %CAPITOLO 1
		\section{Sistema Complesso}
			\begin{definition}
				\textit{Sistema Complesso} è un sistema dinamico composto da sottosistemi interagenti tra loro, chiamati agenti.
			\end{definition}
			Per lo studio di un sistema complesso si usa solitamente un approccio olistico, ossia si studiano prevalentemente le proprietà macroscopiche del sistema totale, senza considerare i singoli sottosistemi.
			Un'osservazione importante che va effettuata è che un modello di sistema complesso \textbf{prevede}, non descrive.
			\begin{definition}
				Lo spazio degli stati dinamici del sistema è detto spazio delle fasi.
			\end{definition}
			\begin{definition}
				I gradi di libertà di un sistema sono dati da $\# d.o.f.=\frac{dimensione dello spazio}{2}$
			\end{definition}
			Per un numero elevato di gradi di libertà è possibile utilizzare l'approccio della meccanica statistica.
			Alcune delle proprietà principali dei sistemi complessi sono:
			\begin{itemize}
				\item \textbf{complessità}: presenza di molti d.o.f. (molti agenti)
				\item \textbf{proprietà emergenti}: derivano dal grande numero di agenti. Ad esempio possiamo definire \textit{fluido} un insieme di molte particelle ma la particella singola non può essere fluida.
				\item \textbf{autorganizzazione}: i sistemi complessi sono ibridi, ossia metà stocastici e metà deterministici. Per studiarli devo dare ugual peso a entrambi gli aspetti.
			\end{itemize}
			La complessità dei sistemi fa si che per definirne uno stato occorra molta \emph{informazione}.
			Ogni sistema complesso fornisce un \emph{feedback} rispetto alle condizioni inziali che sono fornite.
			In particolare, si parla di \emph{feedback positivo} se le condizioni iniziali portano il sistema a "esplodere", ossia ad allontanarsi inesorabilmente dall'origine, mentre si parla di \emph{feedback negativo} quando dopo un certo periodo di tempo il sistema ritorna alle condizioni iniziali.
			\begin{definition}
				Un sistema a feedback negativo è detto in equilibrio dinamico.
			\end{definition}
		
		\section{Teoria di Ljapunov}
			In un sistema classico, una volta scritta la lagrangiana (o hamiltoniana) del sistema e ottenute le \emph{equazioni del moto}, è cosa fatta determinarne l'evoluzione nel tempo (traiettorie).
			Nei sistemi complessi, tuttavia, non è possibile utilizzare un approccio deterministico: si parla infatti di \emph{caos deterministico}.
			Questo caos è causato soprattutto dalle fluttuazioni intrinseche dei sistemi complessi, le quali li rendono particolamente sensibili alle condizioni iniziali.
			Si consideri sistema alle condizioni iniziali $x_{0}$.
			Dopo un tempo $t$, si troverà naturalmente il sistema in una posizione $x(t)$ determinata dalle condizioni iniziali.
			Si assuma ora la presenza di fluttuazioni sulle condizioni iniziali $x_{0}+\delta_{0}$: il sistema evolverà ora come $x(t)+\delta(t)$.
			La teoria vuole che le fluttuazioni seguano l'andamento
			\begin{equation*}
				\delta(t)\simeq\delta_{0}e^{\lambda t}
			\end{equation*}
			dove il coefficiente $\lambda$ è detto \emph{esponente di Ljapunov}.
			Il calcolo di questo parametro non è banale, pertanto non verrà dimostrato ma solo riportato.
			\begin{theorem}
				$\lambda=\lim_{\delta\to0,t\to\infty}\frac{1}{t}\ln\left\lVert \Phi^{t}(x+\delta)-\Phi^{t}(x) \right\rVert$
			\end{theorem}
			Nonostante il limite precendente appaia complicato, nella maggior parte dei casi è possibile utilizzare l'approssimazione $\lambda\simeq\frac{1}{t}\sum_{k}\ln\frac{\delta_{k}}{\delta_{0}}$, dove $k$ indicizza una traslazione temporale $\Delta t$. 
			Per comprendere i limiti dell'approssimazione precedente si può notare come $\delta_{0}e^{\lambda t}=o(1)$, quindi $\ln\delta_{0}+\lambda t=0$.
			\begin{definition}
				$t=-\frac{\ln\delta_{0}}{\lambda}$ tempo di predittività del modello	
			\end{definition}
			Si può notare come:
			\begin{itemize}
				\item l'esponente di Ljapunov è una proprietà dell'orbita, non del punto, ed è quindi necessario interagire su tempi lunghi;
				\item un'alta sensibiltà alle condizioni iniziali implica una scarsa predittività;
				\item per $\lambda>>1$ è possibile utilizzare l'approccio statistico;
				\item le proprietà sono locali (ma non così tanto locali).
			\end{itemize}
			Non è possibile conoscere a priori il segno di $\lambda$.
			Il \emph{caos deterministico}, ovviamente, si ottiene solo se $\lambda>0$ (l'esponenziale esplode) in un insieme a misura finita.
			Ne consegue che le orbite debbano espandersi rimanendo limitate, fenomeno noto come \emph{stretching-folding}, che comporta la conservazione di una misura (volume).
			\begin{theorem}
				di Poincarè (del ritorno)
				\\Un sistema dinamico che conserva i volumi su un compatto ritorna arbitrariamente vicino alle condizioni iniziali (feedback negativo).
				\label{theorem:poincare}
			\end{theorem}
		
		\section{Costruzione di un modello}
			Punto fondamentale di un sistema complesso è costruire un modello che riesca a riprodurre le sue caratteristiche fondamentali, per poi studiarlo.
			Innanzitutto, per prevedere un sistema occorre:
			\begin{itemize}
				\item un modello (matematico) per l'evoluzione;
				\item una conoscenza dello stato presente (o passato) del sistema \emph{sufficiente} ad inizializzare il modello;
			\end{itemize}
			\begin{figure}[H]
				\centering
				\begin{tikzpicture}
				\node[ellipse, draw, align=center] (a) at (0,4) {Problema di\\interesse};
				\node[ellipse, draw, align=center] (b) at (4,4) {Osservazioni\\sprimentali};
				\node[ellipse, draw, align=center] (c) at (6.1,2) {Modello di\\teoria};
				\node[ellipse, draw, align=center] (d) at (1.9,2) {Predizioni};
				\node[ellipse, draw, align=center] (e) at (11,2) {Caratteristiche\\universali};
				\node[ellipse, draw, align=center] (f) at (6.1,0) {Parametri di\\controllo};
				\node[ellipse, draw, align=center] (g) at (1.9,0) {Diversi scenari\\non compatibili};
				\draw [->] (a) -- (b);
				\draw [->] (b) -- (c);
				\draw [->] (c) -- (d);
				\draw [->] (d) -- (b);
				\draw [->] (c) -- (e);
				\draw [->] (c) -- (f);
				\draw [->] (g) -- (d);
				\end{tikzpicture}
				\caption{\emph{Schema operativo}}
				\label{figure:schema_operativo}
			\end{figure}
			In Fig.(\ref{figure:schema_operativo}) è presente lo schema operativo della creazione di un modello.
			Il punto di partenza è sempre un problema, la cui osservazione sperimentale fornisce i dati sui quali costruire un modello di teoria .
			Con esso è poi possibile eseguire delle predizioni da confrontare con i dati sperimentale per comprenderne l'affidabilità e gli eventuali scenari incompatibili.
			Ovviamente un buon modello teorico deve avere dei parametri manipolabili (di controllo) e caratteristiche valide universalmente.
			\\
			Si possono distinguere due tipologie di modelli, le quali verranno ora analizzate.
			\subsection{Modelli ad agente}
				La prima tipologia di modello sono i \emph{modelli ad agente}, ossia quei modelli in cui si effettua uno studio di tipo bottom-up (dal particolare al generale).
				Assunzione fondamentale è di avere piena conoscenza sui comportamenti dei singoli agenti e sull'ambiente in cui questi si relazionano.
				Una volta \emph{formalizzati} matematicamente i comportamenti dei singoli è possibile procedere con una \emph{simulazione}, la quale fornirà una possibile evoluzione del sistema.
				È essenziale notare come in questo caso il risultato ottenuto sia solamente uno dei tanti possibili: bisognerà quindi effettuare la simulazione numerose volte e mediare sui risultati ottenuti.
				Riguardo la costruzione del modello, la prima cosa da definire è l'\textit{ambiente} in cui ci si trova. 
				Questo può essere neutro o avere caratteristiche, ad esempio una distribuzione di nutrimento (per sistemi biologici).
				Altro punto fondamentale è definire \textit{spazio e tempo}. 
				Spesso non fa differenza la scelta di spazi e tempi discreti rispetto ai continui, quindi è preferibile assumere una discretizzazione iniziale per poi passare al continuo successivamente.
				Una volta definito lo spazio bisogna poi decidere le condizioni al contorno, ossia il comportamento ai bordi. 
				Si possono avere \textit{barriere} di tre tipi:
				\begin{itemize}
					\item \textbf{riflettenti}, dove si ha un bordo \textit{non} oltrepassabile. Si crea quindi un fenomeno di \textbf{attrattività delle pareti}.
					\item \textbf{periodico}, dove si hanno i bordi coincidenti (esco da una parte e rientro dall'altra). Lo spazio assume in questo caso una forma toroidale.
					\item \textbf{assorbenti}, dove gli oggetti "uscenti" vengono distrutti. In questo caso bisogna di introdurre delle \textit{sorgenti} nel modello per evitare di perdere tutti gli agenti.
				\end{itemize}
				Si nota facilmente come più piccolo sia il modello, più importante sia il contributo degli effetti di bordo.\\
				Nella maggior parte dei sistemi non tutti gli agenti hanno le stesse caratteristiche: si definiscono allora \textbf{classi} di appartenenza, legate tra loro da relazioni matematiche.
			\subsection{Modelli a equazioni}
				La seconda ed ultima tipologia di sistema complesso è data dai \emph{modelli a equazioni}, ossia quei modelli in cui si effettua uno stduio di tipo top-down (dal generale al particolare).
				In questo caso si assume di non avere conoscenza sui singoli agenti ma di possedere informazioni di carattere puramente macroscopico, dette \emph{osservabili} del sistema.
				Tipicamente, gli osservabili sono legati tra di loro tramite equazioni differenziali le quali, una volta integrate, forniscono un'evoluzione del sistema nel tempo.
				In questo caso il risultato ottenuto rappresenta già una media di tutti i risultati possibili: le fluttuazioni del sistema provocheranno quindi uno scostamento da questo valore.
				Ovviamente, più tempo si farà evolvere il sistema, più rilevante sarà l'effetto delle fluttuazioni e meno preciso sarà il risultato della previsione.

		\section{Distribuzioni}
		Per l'analisi matematica dei sistemi è utile definire le funzioni di distribuzione, le quali sono indicatori della frequenza di avvnimento di un fenomeno.
		\begin{definition}
			Gaussiana\\$\rho(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$
		\end{definition}
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}
				\begin{axis}[
					xmin = -3, xmax = 3,
					ymin = 0, ymax = 1.1,
					samples = 200,
					smooth,
					thick,
					xlabel = {$x$},
					ylabel = {$\rho(x)$},]
					\addplot[
						domain = -3:3,
					] {e^(-x^2)};
				\end{axis}
			\end{tikzpicture}
			\caption{\emph{Gaussiana.}}
			\label{figure:gaussiana}
		\end{figure}
		La gaussiana, riportata in Fig. (\ref{figure:gaussiana}), è nota come la distribuzione degli errori ed è tra le più importanti funzioni della fisica.
		Caratteristica principale è la sua discesa molto veloce superata una distanza pari a $\sigma$ dal valore medio.
		\begin{definition}
			Esponenziale\\$\rho(x)=\frac{1}{k}e^{-\frac{x}{k}}$
		\end{definition}
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}
				\begin{axis}[
					xmin = 0, xmax = 5,
					ymin = 0, ymax = 1.1,
					samples = 200,
					smooth,
					thick,
					xlabel = {$x$},
					ylabel = {$\rho(x)$},]
					\addplot[
						domain = 0:5,
					] {e^(-x)};
				\end{axis}
			\end{tikzpicture}
			\caption{\emph{Esponenziale.}}
			\label{figure:esponenziale}
		\end{figure}
		L'esponenziale, riportato in Fig. (\ref{figure:esponenziale}), è la distribuzione emergente dalla meccanica statistica (fattori di Boltzmann).
		\begin{definition}
			Potenza\\$\rho(x)\propto\frac{1}{x^a}$, con $a>0$
		\end{definition}
		\begin{figure}[H]
			\centering
			\begin{tikzpicture}
				\begin{axis}[
					xmin = 0, xmax = 5,
					ymin = 0, ymax = 5,
					samples = 200,
					smooth,
					thick,
					xlabel = {$x$},
					ylabel = {$\rho(x)$},]
					\addplot[
						domain = 0.1:5,
					] {x^(-2)};
				\end{axis}
			\end{tikzpicture}
			\caption{\emph{Potenza.}}
			\label{figure:potenza}
		\end{figure}
		La potenza, riportata in Fig. (\ref{figure:potenza}), è una distribuzione che possiede un'importanate proprietà, detta \emph{invarianza di scala}.
		\begin{theorem}
			Invarianza di scala:\\
			se $\rho(x)\propto\frac{1}{x^a}$ allora posto $y=\lambda x$ si ha $\rho(y)=\frac{\lambda^a}{x^a}\propto\frac{1}{y^a}$
		\end{theorem}
		\begin{definition}
			Momenti di una distribuzione:\\
			$<x^k>=\int_{-\infty}^{+\infty}x^k\rho(x)dx$
		\end{definition}
		\begin{theorem}
			Limite centrale:\\
			Siano ${x_k}$ variabili casuali indipendenti, allora:\\
			$\lim_{N\to\infty}z=\frac{1}{\sqrt{N}}\sum_{k=1}^{N}x_k=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{z^2}{2\sigma^2}}$
		\end{theorem}

		\section{Esempi}
			\subsection{Automa cellulare}
				Un sistema che vuole simulare l'evoluzione di una popolazione in spazi e tempi discreti è detto automa cellulare.
				Si vuole ora creare un automa cellulare con le seguenti caratteristiche:
				\begin{itemize}
					\item effetto di \textbf{riproduzione}: consiste in un aumento del numero di individui che si riflette nell'espansione esponenziale del sistema (effetto comune in natura purchè le risorse siano sufficienti), ossia
						\begin{equation*}
							\Delta n(t) \propto n(t)
						\end{equation*}
					\item effetto di \textbf{competizione}: limita la crescita della popolazione.
						Un individuo compete coi suoi simili, quindi il contributo competitivo sarà del tipo
						\begin{equation*}
							\Delta n(t) \propto -n^2(t)
						\end{equation*}
				\end{itemize}
				Assunzione fondamentale di questo modello è che ogni individuo possa incontrare tutti quegli altri, irrealistico in quanto in una rete sociale la probabilità di incontri varierebbe da individuo a individuo.
				In un modello continuo si avrebbe
				\begin{equation*}
					n\left(t+\Delta t\right)=n(t)+\left(an(t)-bn^2(t)\right)\Delta t
				\end{equation*}
				dove $\Delta t$ rappresenta il tempo in cui la popolazione evolve (teoria del campo medio), $a$ è il tasso di riproduzione e $b$ il tasso di incontri, questi ultimi assunti costanti.
				Nel limite $\Delta t\to 0$ si ottiene l'\emph{equazione logistica}
				\begin{equation}
					\dot{n}(t)=an(t)\left(1-\frac{b}{a}n(t)\right)
					\label{equation:equazione_logistica}
				\end{equation}
				che altro non è che la rappresentazione continua della \emph{mappa logistica}
				\begin{equation}
					x_{n+1}=rx_{n}\left(1-x_n\right)
					\label{equation:mappa_logistica}
				\end{equation}
				ossia la rappresentazione dinamica non lineare più semplice che degenera in un moto caotico, resa pubblica nel 1976 dal biologo Robert May.\\
				La stabilità del sistema si ha ovviamente per $n=\frac{b}{a}$ e la soluzione analitica del problema diventa
				\begin{equation*}
					n(t)=\frac{an_{0}}{\left(a-bn_{0}\right)e^{-at}+bn_{0}}
				\end{equation*}
				riscrivibile nella forma di \emph{funzione logistica}
				\begin{equation}
					f(t)=\tanh\frac{t}{2}
					\label{equation:funzione_logistica}
				\end{equation}
				\begin{figure}[H]
					\centering
					\begin{tikzpicture}
						\begin{axis}[
							xmin = -7, xmax = 7,
							ymin = -1.1, ymax = 1.1,
							samples = 200,
							smooth,
							thick,
							xlabel = {$t$},
							ylabel = {$f(t)$},]
							\addplot[
								domain = -7:7,
							] {tanh(x/2)};
						\end{axis}
					\end{tikzpicture}
					\caption{\emph{Funzione logistica.}}
					\label{figure:funzione_logistica}
				\end{figure}
				Si può osservare come i limiti $f(t)=\pm 1$ rappresnetino due stati fissi mentre la zona centrale sia di transizione, quindi per $f(t)=0$ si avrà la massima variazione.
			\subsection{Random Walk 1D}
				Il modello più basilare di sistema complesso è sicuramente la random walk su una retta, ossia un punto che ogni istante di tempo decide in maniera casuale se spostarsi a destra o a sinistra.
				Sia $p=\frac{1}{2}$ la probabilità di muoversi verso destra (quindi anche a sinistra) di un passo $\Delta x$. Si hanno:
				\begin{itemize}
					\item \{R\}: $p(t+\Delta t)=x(t)+\Delta x$
					\item \{L\}: $p(t+\Delta t)=x(t)-\Delta x$
				\end{itemize}
				Dopo \textit{n} passi si ha quindi $p(n\Delta t)=x_0+\sum_k\xi_k\Delta x$ con $\xi(t)=\pm 1$.
				Inoltre si può verificare che $<\xi_k>=0$, $<\xi_k^2>=1$, $<\xi_k\xi_h>=<\xi_k><\xi_h>, k\neq h$.
				Per il teorema del limite centrale si ha:
				$\sum_k^n\xi_k\Delta x=\sqrt{n\Delta t}\left(\frac{1}{\sqrt{n}}\sum_k^n\xi_k\right)\frac{\Delta x}{\sqrt{\Delta t}}=\frac{1}{\sqrt{2\pi Dt}}e^{-\frac{z^2}{2Dt}}$, con $z$ variabile gaussiana.
				Introducendo il concetto di diffusione:\\
				\begin{definition}
					Diffusione. $D=\frac{\Delta x^2}{\Delta t}$
				\end{definition}
				si può descrivere l'evoluzione del sistema come $x(t)=x_0+z\sqrt{Dt}$
				Si utilizza $\sqrt{n}$ per normalizzare in quanto è l'unico esponente non divergente.
				La varianza della gaussiana cresce nel tempo, infatti calcolando i momenti della distribuzione si trova $<x(t)>=x_0$, $<(x(t)-x_0)^2>=Dt$.
				Se la topologia del sistema fosse una circonferenza (e non una retta), si avrebbe un rilassamento esponenziale a una situazione stazionaria.
				\\Definito un intervallo $-L,L$ sulla retta, la probabilità che il punto vi sca dopo un tempo $t$ è data da:
				\begin{equation}
					P(\left\lvert x\right\rvert >L)=1-\int_{-L}^{L}\frac{1}{\sqrt{2\pi Dt}}e^{-\frac{x^2}{2Dt}}dx
				\end{equation}
				Si può facilmente notare come raddoppiando la distanza $L$ il tempo $t$ quadruplichi.
			\subsection{Random Walk 2D}
				Volendo espandere il modello di random walk ad uno spazio 2D si nota subito come, essendo ogni asse indipendente dall'altro, si possa semplicemente comporre due gaussiane:\\
				\begin{equation*}
					(x,y)\simeq\frac{1}{2\pi\Delta t}e^{-\frac{x^2+y^2}{2\Delta t}}=\rho(x,y,t)
				\end{equation*}
				Dove la diffusione segue la definizione precedente ed è la stessa in tutte le direzioni.
				La funzione $\rho(x,y,t)$ rappresnta di fatto la probabilità che la il soggetto in analisi si trovi in un volume $\Delta x\Delta y$.
				Si può riscrivere la relazione precedente in coorfinate polari ottenendo:
				\begin{equation*}
					\rho(r,\theta,t)=\frac{r}{2\pi\Delta t}e^{-\frac{r^2}{2\Delta t}}
				\end{equation*}
				studiando più semplicemente l'allontanamento dall'origine.
				In particolare, l'allontanamento medio risulta:
				\begin{equation*}
					<r>=\int_0^\infty\rho(r,\theta,t)rdr=\sqrt{\frac{\pi}{2}\Delta t}
				\end{equation*}
				e la densità diminuisce quindi esponenzialmente.
			\subsection{Random Walk non omogenea}
			Si consideri ora una random walk 1D con probabilità non uniforme in un reticolo di passo $\Delta x$.
			Sia $\epsilon$ un parametro e si definiscano le probabilità:
			\begin{equation*}
				\begin{cases}
					p_{++}=p_{--}=\frac{1}{4}(1+\epsilon x)\quad x\geq 0\quad\Rightarrow x\rightarrow x\pm 2\Delta x\\
					p_+=p_-=\frac{1}{4}(1-\epsilon x)\quad x<0\quad\Rightarrow x\rightarrow x\pm \Delta x
				\end{cases}
			\end{equation*}
			Si può verificare facilmente come le probabilità siano ben definite.
			Il sistema tende a muoversi più velocemente nel verso positivo delle \textit{x} e più lentamente nel verso opposto, assomigliando a una scatola con aria a diversa temperatura: vi è quindi un equilibrio locale (ogni nodo è identico).
			Si può osservare come:
			\begin{equation*}
				\begin{split}
					<\Delta x>&=0\\
					<\Delta x^2>&=(4\Delta x^2)(p_{++}+p_{--})+\Delta x^2(p_++p_-)=\left(\frac{5}{2}+\frac{3}{2}\epsilon x\right)\Delta x^2
				\end{split}
			\end{equation*}
			Ogni passo ho un \textit{enemble} differente, quindi lo spazio non è omogeneo.
			Ponendo $T(x)=<\Delta x^2>$ come funzione corrispondente alla temperatura fisica, si ottiene un gradiente costante:
			\begin{equation*}
				\frac{dT}{dx}=\frac{3}{2}\epsilon\Delta x^2
			\end{equation*}
			Questo gradiente si ritrova spesso in natura, ad esempio i batteri variano la velocità di movimento (casuale) dei loro flagelli seguendo un gradiente di cibo.
			Per essere apprezzabile la variazione di temperatura deve essere tale che $\Delta T=\frac{\partial T}{\partial x}\Delta x\propto\Delta x^3$ e in un limite continuo si ottiene:
			\begin{equation*}
				\begin{split}
					\frac{\partial p}{\partial t}&=\frac{1}{2}\frac{\partial p}{\partial x}T(x)\frac{\partial p}{\partial x}p(x,t)\\
					\frac{d<x>}{dt}&=\frac{1}{2}\int x\frac{\partial p}{\partial x}T(x)\frac{\partial p}{\partial x}p(x,t)>0\quad \frac{\partial T}{\partial x}>0
				\end{split}
			\end{equation*}
			Andando a calcolare media e mediana del sistema si nota come:
			\begin{equation*}
				\begin{split}
					\int xp(x,t)dx&>0\\
					-\int_{-L}^0p(x,t)dx&+\int_0^Lp(x,t)dx<0
				\end{split}
			\end{equation*}
			In conclusione la maggior parte delle particelle si trova nella zona fredda ($x<0$), come vuole la fisica, ma la media della distribuzione si trova nella zona calda ($x>0$).
			\subsection{Dinamica generica di interazione}
				Consideriamo di avrere $n_{0}$ individui iniziali su una griglia (spazio discretizzato) che si muovono seguendo una Random Walk 2D e soggetti alle seguenti restrizioni:
				\begin{itemize}
					\item se un individuo ha spazio sufficiente, si riproduce in un tempo $\Delta t$, allora si deve avere $\Delta n(t)\propto n(t)$;
					\item se due individui competono per lo stesso spazio, uno dei due soccombe con una certa probabilità $p$, il che implica $\Delta n(t)\propto -n^{2}(t)$;
				\end{itemize}
				Si osservi come il termine $n^{2}(t)$ conti il numero di coppie.
				Definita la scala di tempo $\Delta t$, in un modello continuo si deve avere (teoria del campo medio):
				\begin{equation*}
					n(t+\Delta t)=n(t)+\left(an(t)-bn^{2}(t)\right)\Delta t
				\end{equation*}
				con $a$ parametro di riproduzione e $\frac{b}{a}$ competizione nella popolazione (dato dall'ambiente).
				Imponendo l'equilibrio
				\begin{equation*}
					\dot{n}(t)=an(t)\left(1-\frac{b}{a}n(t)\right)=0
				\end{equation*}
				si ottengono i punti critici $n=0$, instabile, e $n=\frac{a}{b}$ stabile.
				La soluzione al sistema è quindi del tipo
				\begin{equation}
					n(t)=\frac{an_{0}}{\left(a-bn_{0}\right)e^{-at}+bn_{0}}
				\end{equation}
				e la funzione logistica del sistema è
				\begin{equation}
					f(t)=\frac{1-e^{-t}}{1+e^{-t}}=\tanh\frac{t}{2}
				\end{equation}
			\subsection{Catmap}
				Consideriamo un gatto su un toro $\Pi^{2}$ (ciambella) in gradi di muoversi secondo la:
				\begin{equation*}
					\left(
					\begin{matrix}
						x_{n} \\
						y_{n} 
					\end{matrix}
					\right)=
					\left(
					\begin{matrix}
						2 & 1\\
						1 & 1 
					\end{matrix}
					\right)
					\left(
					\begin{matrix}
						x_{n-1} \\
						y_{n-1} 
					\end{matrix}
					\right)
				\end{equation*}
				Risulta ovvio come
				\begin{equation*}
					\det
					\left(
						\begin{matrix}
							2 & 1\\
							1 & 1 
						\end{matrix}
					\right)=1
				\end{equation*}
				quindi si conservino le aree.
				Calcolo degli autovalori:
				\begin{equation*}
					\det
					\left(
						\begin{matrix}
							2-\lambda & 1\\
							1 & 1-\lambda
						\end{matrix}
					\right)=\lambda^{2}-3\lambda+1=0
				\end{equation*}
				e si ottengono
				\begin{equation*}
					\begin{cases}
						\lambda_{\pm}=\frac{3\pm\sqrt{5}}{2}\\
						\lambda_{+}\lambda_{-}=1
					\end{cases}
				\end{equation*}
				Il sistema dilata densamente lungo la direzione $v_{+}$ dell'autovettore $\lambda_{+}>1$.
				Dato un vettore iniziale $x_{0}$, $(x_{0}\cdot v_{t})\lambda_{t}^{n} \Rightarrow \ln\lambda_{t}$ è l'esponenziale di Ljapunov.
				\begin{figure}[H]
					\centering
					\begin{tikzpicture}
						\begin{axis}[
							xmin = 0, xmax = 1,
							ymin = 0, ymax = 1,
							smooth,
							thick,
							xlabel = {$x$},
							ylabel = {$y$},]
							\addplot [red, only marks, mark=*, samples=1000, domain=0:1, mark size=0.75] {rnd};
							\draw [fill=black] (0.4,0.4) rectangle (0.6,0.6);
							\draw [fill=green] (0.9,0.7) rectangle (1,0.9);
							\draw [fill=green] (0,0.7) rectangle (0.1,0.9);
						\end{axis}
					\end{tikzpicture}
					\caption{\emph{Catmap.}}
					\label{figure:catmap}
				\end{figure}
				In Fig.(\ref{figure:catmap}) è rappresentata un'applicazione della catmap su un insieme di punti.
				Si può notare come una volta fatto evolvere il sistema partendo dall'area nera, questo non ritorni nella condizione iniziale applicando la trasformazione inversa (area verde).
				\\
				Problema: data una distribuzione di punti $\rho_{0}$, cosa succede a $\rho_{0}(T^{n}x)$?
				\\
				Per definizione, data una distribuzione $\rho(x)$, questa deve essere normalizzata $\int_{\Pi^{2}}\rho(x)dx=1$.
				L'equazione di continuità permette di imporre la conservazione del numero di particelle:
				\begin{equation*}
					\rho(x,n)=\rho_{0}\left(T^{-n}x\right)\left\lvert\frac{\partial T^{-n}}{\partial x}\right\rvert 
				\end{equation*}
				in cui si riconosce $\left\lvert\frac{\partial T^{-n}}{\partial x}\right\rvert=
				\det
				\left(
					\begin{matrix}
						2 & 1\\
						1 & 1 
					\end{matrix}
				\right)=1$, quindi $\rho_{0}\left(T^{n}x\right)$ evolve in una distribuzione di particelle.
				Si può ora constatare che, se $I(x)$ è un osservabile del sistema, vale la relazione:
				\begin{equation*}
					<I>(n)=\int I(x)\rho(x,n)dx
				\end{equation*}
				La teoria suggerisce l'esistenza di una distribuzione invariante $\rho_{s}\left(T^{-n}x\right)=\rho_{s}$.
				Sia ora $\chi_{A}(x)$ la funzione caratteristica del dell'insieme $A$, e $\rho_{0}(y)=\frac{\chi_{A}(y)}{m(A)}$, $I(x)=\chi_{B}(x)$.
				L'integrale precedente diviene:
				\begin{equation}
					\begin{split}
						<I>(n)=\int\chi_{B}(x)\frac{\chi_{A}T^{-n}x}{m(A)}dx&=\int_{B}\frac{\chi_{A}T^{-n}x}{m(A)}dx=\\
						=\frac{1}{m(A)}\int_{T^{B}}\chi_{A}(y)dy&=\frac{1}{m(A)}m(A)m(B)=m(B)\\
						m(B)&=\int\chi_{B}(x)\rho_{s}(x)dx
					\end{split}
				\end{equation}
				e si è così dimostrato il teorema \ref{theorem:poincare}.
			\subsection{Modello economico}
				Si vuole ora costruire un primo modello legato alla realtà simulando, per quanto grossolanamente, l'economia globale.\\
				Supponiamo di avere \textit{M} individui con \textit{n} soldi ciascuno, che si muovono su una griglia secondo una Random Walk 2D.
				Ogni qualvolta due individui si trovino sulla stessa cella questi si scambiano 1 soldo con probabilità $p=\frac{1}{2}$.\\
				\textbf{Caso limite}: se si incontra un povero ($n=0$), si gioca lo stesso (gioco scorretto) per permettere a tutti di uscire dalla povertà.
				Il sistema ha quindi i seguenti limiti:
				\begin{equation*}
					\begin{cases}
						\sum_kn_k=N\\
						n_k\geq 0
					\end{cases}
				\end{equation*}
				con \textit{N} costante, quindi non si ha creazione/distruzione di denaro.
				La probabilità di trovare un individuo con n soldi è:
				\begin{equation*}
					p(n)=\frac{\binom{M+N-2-n}{M-2}}{\binom{M+N-1}{N-1}}
				\end{equation*}
				e, ponendo $\overline{n}=\frac{N}{M}$, si può calcolare:
				\begin{equation}
					\lim_{M\to\infty}\frac{1}{\overline{n}}\left( 1-\frac{n}{M}\right)^M=\frac{1}{\overline{n}}e^{-\frac{n}{\bar{n}}}
				\end{equation}
				quindi la probabilità decresce esponenzialmente.\\
				\begin{figure}[H]
					\centering
					\begin{tikzpicture}
						\begin{axis}[
							xmin = 0, xmax = 6,
							ymin = 0, ymax = 1.1,
							samples = 200,
							smooth,
							thick,
							xlabel = {$n$},
							ylabel = {$p(n)$},]
							\addplot[
								domain = -2:6,
							] {e^(-x)};
						\end{axis}
					\end{tikzpicture}
					\caption{\emph{Andamento esponenziale.}}
					\label{figure:modello_economico}
				\end{figure}
				Il modello prevede quindi:
				\begin{itemize}
					\item molti poveri e pochi ricchi (ma praticamente nessun super-ricco)
					\item esiste un tempo in cui un povero diventa ricco (e viceversa)
					\item simile alla distribuzione di energia di Maxwell-Boltzmann
					\item se chi è ricco pagasse di più si otterrebbe una curva a campana
				\end{itemize}
				Tuttavia osservando i dati sperimentali si nota una discrepanza: nella realtà la probabilità sembra seguire una legge a potenza piuttosto che esponenziale.
				Pur non trovando riscontro nella realtà, si è appena dimostrato stocasticamente il fattore di Boltzmann $e^{-\beta\epsilon}$.
				Si può quindi pensare il denaro come un'\emph{energia interna} al singolo mentre la probabilità di scambio rappresenta la \emph{temperatura statistica} del sistema.
			\subsection{Modello economico evoluto}
				Per adattare il modello precedente alla realtà si introduce una microdinamica sugli scambi di denaro.\\
				Sia $\pi_\pm$ la probabilità di guadagnare $\pm 1$ soldi se un soggetto ne possiede \textit{n}. Il sistema possiede una \textit{struttura di catena}:
				\begin{definition}
					Struttura di catena.\\
					Un modello ha struttura di catena quando il flusso in una direzione implica un secondo flusso nella direzione opposta.
				\end{definition}
				A causa di questa struttura, all'equilibrio si deve avere:
				\begin{equation*}
					\pi_+(n-1)p(n-1)+\pi_-(n+1)p(n+1)=\pi_+(n)p(n)+\pi_-(n)p(n)
				\end{equation*}
				e in particolare è verificato il \textit{bilancio dettagliato}:
				\begin{equation}
					\pi_+(n-1)p(n-1)=\pi_-(n)p(n)\quad \forall n\geq 1
				\end{equation}
				Normalizzata la distribuzione è possibile iterare il tutto:
				\begin{equation*}
					p(n)=\prod_{k=1}^n\frac{\pi_+(k-1)}{\pi_-(k)}p(0)
				\end{equation*}
				Riscrivendo un maniera più comoda il bilancio dettagliato, si può poi procedere:
				\begin{equation*}
					\pi_+(n-\frac{1}{2})p(n-\frac{1}{2})=\pi_-(n+\frac{1}{2})p(n+\frac{1}{2})
				\end{equation*}
				\begin{equation*}
					\begin{split}
						[\pi_+(n)-\pi_-(n)]p(n)-\frac{1}{2}\frac{\partial}{\partial n}[\pi_+(n)-\pi_-(n)]p(n)\simeq 0\\
						ap(n)+\frac{\partial}{\partial n}(bn)p(n)\simeq 0
					\end{split}
				\end{equation*}
				Si possono notare ora le seguenti dipendenze, introducendo la coppia di parametri costanti \textit{(a, b)}:
				\begin{equation*}
					\begin{cases}
						\pi_+(n-1)-\pi_-(n)\simeq a\\
						\pi_+(n)\simeq bn-\frac{a}{2}\\
						\pi_-(n)\simeq bn+\frac{a}{2}
					\end{cases}
				\end{equation*}
				Cercando ora l'andamento di $p(n)$:
				\begin{equation}
					\begin{split}
						p(n)-p(n-1)&=\left(\frac{bn-\frac{a}{2}}{bn+\frac{a}{2}}-1\right)p(n-1)\\
						\frac{dp}{dn}&=-\frac{a}{bn}p(n-1)\\
						\Rightarrow\lim_{n\to\infty}p(n)&\propto n^{-\frac{a}{b}}
					\end{split}
				\end{equation}
				si ottiene esattamente l'andamento a potenza ricercato.\\
				\begin{figure}[H]
					\centering
					\begin{tikzpicture}
						\begin{axis}[
							xmin = 0, xmax = 6,
							ymin = 0, ymax = 6,
							samples = 200,
							smooth,
							thick,
							xlabel = {$n$},
							ylabel = {$p(n)$},]
							\addplot[
								domain = 0.1:6,
							] {1/(x^2)};
						\end{axis}
					\end{tikzpicture}
					\caption{\emph{Andamento a potenza.}}
					\label{figure:modello_economico_evoluto}
				\end{figure}
			\subsection{La rovina di un giocatore}
				Si consideri un giocatore d'azzardo con a disposizione un capitale \textit{k} e che vuole arrivare ad un capitale \textit{M}.
				Il gioco finisce ai ``bordi'' (barriera assorbente) per $k=0$ (giocatore rovinato) o per $k=M$ (giocatore felice).
				Siano $p$ la probabilità di guadagnare, $q=1-p$ la probabilità di perdere, $P_M(k)$ la probabilità di arrivare al capitale \textit{M} partendo da \textit{k}.
				Come nel modello economico evoluto si ha:
				\begin{equation*}
					P_M(k)=pP_M(k+1)+qP_M(k-1)
				\end{equation*}
				con i vincoli
				\begin{equation*}
					\begin{cases}
						P_M(0)=0\\
						P_M(M)=1
					\end{cases}
				\end{equation*}
				Ragionando per induzione si ottiene:
				\begin{equation*}
					P_M(k+1)-P_M(k)=\frac{q}{p}\left[P_M(k)-P_M(k-1)\right]=\left(\frac{q}{p}\right)^kP_M(1)
				\end{equation*}
				\begin{equation}
					P_M(k)=\frac{1-\left(\frac{q}{p}\right)^k}{1-\left(\frac{q}{p}\right)^M}
				\end{equation}
				Inoltre,
				\begin{equation}
					P_\infty(k)=1-\left(\frac{q}{p}\right)^k
				\end{equation}
				In particolare, considerando un gioco equo, si può notare come $P_M(k)=\frac{k}{M}$ e quindi:
				\begin{itemize}
					\item il gioco è alla pari solo se $k\simeq M$
					\item la probabilità di vincita aumenta all'aumentare del proprio capitale rispetto a quello avversario
					\item contro un casinò ($M\to\infty$) la probabilità di vincita è evidentemente nulla anche in caso di gioco equo (assunzione oltretutto inverosimile)
				\end{itemize}
	
	\chapter{Entropia e Informazione} %CAPITOLO 2
		\section{Probabilità}
			Data una distribuzione di probabilità $\rho(x)$ normalizzata (integrale sul dominio uguale a $1$) è possibile procedere con le seguenti definizioni:
			\begin{definition} Probabilità:\\
				$p(x\in[a,b])=\int_{a}^{b}\rho(x)dx$
			\end{definition}
			\begin{definition} Probabilità cumulata:\\
				$p(x\leq a)=\int_{-\infty}^{a}\rho(x)dx$
			\end{definition}
			\begin{definition}
				Probabilità stazionaria\\
				La probabilità stazionaria è il numero di volte che un evento accade in una sequenza.
			\end{definition}
			\begin{theorem}
				legge dei grandi numeri\\
				Siano A e B due eventi distinti (osservati N volte), allora si ha che\\
				$\lim_{N\to\infty}\frac{p(AB)}{p(A)}=p(B/A)$
			\end{theorem}
			\subsection{Ranking distribution}
				\begin{definition}
					Sia $x$ una variabile aleatoria con un sample $\{x_{1},\ldots,x_{n}\}$ di osservazioni ordinate tali che $x_{1}\geq x_{2}\geq\ldots$.
					Allora $x_{j}=f(j)$ è detta ranking distribution.
				\end{definition}
				Solitamente tale distribuzione è normalizzata in modo che $y_{j}=\frac{x_{j}}{x_{1}}$.
				Per definizione la frequenza di un evento è $\frac{j}{n}$, quindi la distribuzione cumulata risulta
				\begin{equation}
					F(x_{j})=1-\frac{j}{n}=1-\frac{J(x_{j})}{n}
				\end{equation}
				con $J(x_{j}$ inverso del ranking.
				La funzione di distribuzione sarà quindi
				\begin{equation}
					p(x)=-\frac{1}{n}\frac{dJ}{dx}
				\end{equation}
		
		\section{Entropia}
			Si supponga di voler calcolare l'incertezza di una distribuzione di probabilità $p_{1},\ldots,p_{n}$ per gli eventi $\{x_{1},\ldots,x_{n}\}$.
			Si assuma:
			\begin{itemize}
				\item $H(p_{1},\ldots,p_{n})$ continua;
				\item se $p_{j}=\frac{1}{n}$ allora $H(\frac{1}{n},\ldots,\frac{1}{n})$ è monotona crescente;
				\item Dati gli eventi composti $y_{1}=\{x_{1},\ldots,x_{m}\}$, $y_{2}=\{x_{m+1},\ldots,x_{m+k}\}$ con probabilità $P(y_{i}/x_{i})=\frac{p_{i}}{w_{i}}$, allora 
					\\$H(p_{1},\ldots,p_{n})=H(w_{1},\ldots,w_{n})+w_{1}H\left(\frac{p_{1}}{w_{1}},\ldots,\frac{p_{m}}{w_{1}}\right)+w_{2}H\left(\frac{p_{2}}{w_{2}},\ldots,\frac{p_{m}}{w_{2}}\right)+\ldots$;
			\end{itemize}
			La soluzione è del tipo $H(p_{1},\ldots,p_{n})=-k_{s}\sum_{i}p_{i}\ln(p_{i})$ dove si definisce
			\begin{definition}
				$S=-k_{s}\sum_{i}p(x_i)\ln p(x_i)$ entropia di informazione (di Shannon)
				\label{equation:entropia}
			\end{definition}
			con $k_{s}=\frac{1}{\ln2}$ costante di Shannon.
			Si può notare come $H(p_{1},\ldots,p_{n})$ sia massima per $p_{j}=\frac{1}{n}$.
			Fissato $\bar{x}=\sum_{j}x_{j}p_{j}$, l'entropia è massimizzabile utilizzando i moltiplicatori di lagrange:
			\begin{equation*}
				\delta H=-\sum_{i}\delta p(x_i)\ln p(x_i)+\lambda\sum_{j}x_{j}\delta p_{j}=0
			\end{equation*}
			il che implica $-\ln p_{j}+\lambda x_{j}=0$, con soluzione
			\begin{equation}
				p_{j}=\frac{e^{\lambda x_{j}}}{\sum_{j}e^{\lambda x_{j}}}
			\end{equation}
			con $\lambda\simeq -\frac{1}{\bar{x}}$ (risultato fondamentale della meccanica statistica).
			La distribuzione è quindi esponenziale, con $p_{j}\propto e^{-\frac{x_{j}}{\bar{x}}}$.
		
		\section{Informazione}
			\begin{definition}
				Una variabile $x$ a valori discreti $\{x_0,x_1,...\}$ è detta variabile di CODING
			\end{definition}
			Si consideri una sequenza (\textit{codifica}) $\{x_k\}_1^N$: si può assumere $P(\{x_k\})=p(x_1)...p(x_N)$.
			Una codifica è detta \textbf{ottimale} se può descrivere in maniera univoca un'orbita.
			\begin{definition}
				Data una codifica, si definisce $-\ln(x)$ l'informazione portata dal carattere $x$
			\end{definition}
			Si nota subito come più un valore della variabile di coding è probabile, minor informazione questo porti.
			Informaticamente, la misura è circa il numero di bit necessari per memorizzare la sequenza (da qui il fattore $\ln2$ dell'entropia di Shannon).
			L'equazione \ref{equation:entropia} rappresenta quindi l'informazione media portata da un singolo carattere.
			Non bisogna confondere entropia con informazione: la variabile deve avere un significato!
			Data l'indipendenza dei caratteri, si può scrivere l'entropia di una coppia come
			\begin{equation*}
				\begin{split}
					S\left(P_{2}\left(\{x_{k_{1}},x_{k_{2}}\}\right)\right)&=-\sum_{k_{1},k_{2}}P_{2}\left(\{x_{k_{1}},x_{k_{2}}\}\right)\ln{P_{2}\left(\{x_{k_{1}},x_{k_{2}}\}\right)}=\\
					&=-\sum_{k_{1}}P\left(x_{k_{1}}\right)\ln{P\left(x_{k_{1}}\right)}\sum_{k_{2}}P\left(x_{k_{2}}\right)\ln{P\left(x_{k_{2}}\right)}
				\end{split}
			\end{equation*}
			Iterando il ragionamento si giunge alla conclusione che l'entropia di Shannon misura l'aumento di informazione data dall'aggiunta di un carattere.
			\subsection{Matrice stocastica}
				Si è analizzato finora il caso di caratteri indipendenti gli uni dagli altri.
				Tuttavia, per comprendere una sequenza bisogna, in generale, conoscerne la \textit{memoria}, ossia tutte le dipendenze di un evento dagli altri.
				Formalmente, ciò vorrebbe dire che, dati due eventi A e B, $P\left(\{AB\}\right)=P\left(B/A\right)P(A)\neq P(A)P(B)$.
				Si può facilmente osservare come $\lim_{N\to\infty}\frac{P\left(\{AB\}\right)}{P(A)}=P\left(B/A\right)$, dove $N$ rappresenta il numero totale di eventi.
				L'\textit{irreversibilità} di un evento si ha quando la coppia di eventi $AB$ è diversa dalla coppia di eventi $BA$.
				\begin{definition}
					$p_{ij}=p(x_j/x_i)$ matrice stocastica
				\end{definition}
				La matrice stocastica ha per definizione le seguenti proprietà:
				\begin{itemize}
					\item $0\leq p_{ij}\leq 1$
					\item $\sum_jp_{ij}=1$
				\end{itemize}
				Questa matrice è molto importante, essento intrinsecamente legata alla probabilità condizionata, ed è alla base di ogni problema di trasporto.
				Si consideri ora una sequenza infinita e sia $p_i$ la probabilità di avere l'elemento $x_i$ in quella posizione.
				Qual è la probabilità $p_j$ di avere l'elemento successivo?
				Sia \textit{n} il numero di passi per arrivare in posizione \textit{i}, allora:
				\begin{equation}
					p_j^{n+1}=\sum_ip_{ij}p_j^n
				\end{equation}
				Risulta quindi utile il seguente teorema:
				\begin{theorem}
					Esiste un autovettore con autovalore $\lambda_0=1$, ossia\\
					$p_j^s=\sum_ip_{ij}p_j^s$
				\end{theorem}
				Corollari:
				\begin{itemize}
					\item $p_j^s$ è un vettore stazionario situato nel primo quadrante
					\item l'iperpiano $\sum_{i,j}p_{ij}v_i=\sum_iv_i=0$ sono invarianti per $p_{ij}$
					\item $\lambda_i<1\quad\forall i\neq 0$
					\item $p_j^{n+1}=\sum_ip_{ij}p_j^n=1\Leftrightarrow\sum_ip_i^n=1$
				\end{itemize}
			\subsection{Teoria di Markov}
				A questo punto si può calcolare come cambi quantitativamente l'informazione di una catena aggiungendo un carattere.
				\begin{definition}
					Proprietà di Markov (di tempo presente)\\
					$P(\{x_1,...,x_{n+1}\})=P(x_{n+1}/Px_n)P(\{x_1,...,x_{n}\})$
				\end{definition}
				Si può quindi calcolare l'entropia dell'(N+1)esimo passo
				\begin{equation*}
					\begin{split}
						S_{N+1}&=-\sum P\left(\{x_{1}\ldots x_{N+1}\}\right)\ln P\left(\{x_{1}\ldots x_{N+1}\}\right)=\\
						&=-\sum P\left(\{x_{N+1}/x_{N}\}\right)P\left(\{x_{1}\ldots x_{N+1}\}\right)\left[\ln P\left(\{x_{N+1}/x_{N}\}\right)\ln P\left(\{x_{1}\ldots x_{N+1}\}\right)\right]=\\
						&=-\sum P\left(\{x_{1}\ldots x_{N}\}\right)\ln P\left(\{x_{1}\ldots x_{N}\}\right)-\sum_{i,j}p_j^sP\left(x_i/x_j\right)\ln P\left(x_i/x_j\right)
					\end{split}
				\end{equation*}
				ottenendo, nel limite $N>>1$, l'espressione: 
				\begin{equation}
					S_{N+1}=S_N-\sum_{ij}p_j^sp_{ij}\ln p_j
				\end{equation}
				Nei linguaggi l'aggiunta di un carattere non cambia di molto l'entropia (per fortuna, altrimenti sarebbe molto difficile parlarsi, ndr).
				Questa entropia fornisce tuttavia un'importante risultato sulla reversibilità del processo:
				se invertendo il tempo non ho differenza di entropia, allora il processo è \textit{reversibile}, altrimenti no.
				Le \textbf{fluttuazioni} di un sistema \textbf{all'equilibrio} sono sempre un processo \textbf{reversibile}, infatti osservando tale sistema non si riesce a distinguere tra passato e futuro.
				Come esempio per giustificare la precedente affermazione si può prendere un pendolo fisico in assenza di attriti/forse esterne, oppure un \textit{moto browniano}.
				Un esempio grafico puoò essere rappresentato dalla Fig.(\ref{figure:esempio_markov}).
				\begin{figure}[H]
					\centering
					\begin{tikzpicture}[>=latex,every node/.style={draw,circle,minimum width={3em},node distance=6em}]
					\node (a) {A};
					\node [below left of=a] (b) {B}; 
					\node [below right of=a] (c) {C};  
					\draw [<->] (a) -- (b);
					\draw [<->] (b) -- (c);
					\draw [<->] (c) -- (a);
					\end{tikzpicture}
					\caption{\emph{Grafo di esempio reversibilità.}}
					\label{figure:esempio_markov}
				\end{figure}
				Associando la matrice
				\begin{equation*}
					\Pi_{ij} = 
						\begin{pmatrix}
							0 & \frac{1}{2} & \frac{1}{2} \\
							\frac{1}{2} & 0 & \frac{1}{2} \\
							\frac{1}{2} & \frac{1}{2} & 0 
						\end{pmatrix}
				\end{equation*}
				si ha eguale probabilità di transizione in ogni direzione ammessa dal grafo.
				L'evoluzione temporale è data da
				\begin{equation*}
					p_i^{n+1}=\sum_j\Pi_{ij}p_j^n
				\end{equation*}
				e si verifica facilmente che il sistema è reversibile con distribuzione stazionaria
				\begin{equation*}
					\lim_{n\to\infty}p^n=\left(\frac{1}{3},\frac{1}{3},\frac{1}{3}\right)
				\end{equation*}
				Considerando invece la matrice
				\begin{equation*}
					\Pi_{ij} = 
						\begin{pmatrix}
							0 & \frac{1}{3} & \frac{2}{3} \\
							\frac{2}{3} & 0 & \frac{1}{3} \\
							\frac{1}{3} & \frac{2}{3} & 0 
						\end{pmatrix}
				\end{equation*}
				si aumenta la probabilità di percorrere il triangolo in senso antiorario.
				Essendo la distrubuzione stazionaria identica al caso precedente si può studiare la reversibilità con il bilancio dettagliato:
				\begin{equation*}
					\pi_{13}p_3^s = \frac{2}{3} \frac{1}{3} \neq \frac{1}{3}\frac{1}{3} = \pi_{31}p_1^s
				\end{equation*}
				Secondo Onsager, la distribuzione stazionaria corrisponde all'equilibrio quindi, analizzando le fluttuazioni è possibile capire se il sistema sia reversibile o meno.
				Nell'esempio riportato in Fig. (\ref{figure:esempio_markov}) è evidente come la rimozione del punto A non influenzi il sottosistema BC: è questo l'equilibrio dettato dal bilancio dettagliato.
				\\
				In conclusione, la teoria dell'informazione è applicabile quasi in ogni ambito.
				Sono stati effettuati studi sui linguaggi, premiando finlandese e tedesco come lingue più entropiche, e studi sulla musica, che vedono Bach meno entropico di Hindemith.
		
		\section{Esempi}
			\subsection{Utilizzo della misura invariante}
				Sia $x_{n}=2^{n}$ un numero, con $n \geq 1$.
				Qual è la probabilità che esso abbia un $7$ come prima cifra?
				\\Supponendo $2^{n}=7.\cdots\times 10^{k}$, allora $\log{2^{n}}=\log{7.\cdots}+k$.
				Si consideri ora la dinamica
				\begin{equation}
					y_{n+1}=y_{n}+\log2\mod1
					\label{equation:cifre}
				\end{equation}
				che rappresenta sostanzialmente una traslazione nell'intervallo $[0,1]$.
				In questo caso l'esponente di Ljapunov è nullo in quanto non vi è espansione.
				Iterando la \ref{equation:cifre} si ottiene
				\begin{equation*}
					y_{n}=y_{0}+n\log2\mod1
				\end{equation*}
				e la misura invariante risulta quindi una distribuzione uniforme nell'intervallo $[0,1]$.
				Da qui la probabilità $\lim_{n\to\infty}P(7)=\log8-\log7$.
			\subsection{Entropia di una mano di carte}
				Supponiamo di possedere un mazzo di $N$ carte differenti e di pescare da esso $k\leq N$ carte.
				Per calcolare l'entropia di informazione associata alla mano pescata, bisogna innanzitutto calcolare la probabilità di una mano singola.
				Le combinazioni di $k$ carte di un mazzo di $N$ carte sono date dal coefficiente binomiale:
				\begin{equation}
					C=\binom{N}{k}=\frac{N!}{k!(N-k)!}
				\end{equation}
				Assumendo che il mazzo non sia truccato, quindi che ogni estrazione sia equiprobabile, la probabilità di ogni singola mano è $p_{i}=\frac{1}{C}$.
				L'entropia di informazione (o di Shannon) associata ad essa è quindi 
				\begin{equation*}
					S=-k_{S}\sum_{i=1}^{C}p_{i}\ln{p_{i}}=-k_{S}C\left(\frac{1}{C}\ln{\frac{1}{C}}\right)=k_{S}\ln{\frac{N!}{k!(N-k)!}}
				\end{equation*}
				con $k_{S}=\frac{1}{\ln2}$ costante di Shannon.
			\subsection{Broken Stick Model/Modello di Markov}
				Si consideri un segmento di lunghezza unitaria nel quale viene inserito casualmente un punto $x_1\in[0,1]$ secondo una distribuzione uniforme.
				Si scarti ora il segmeno $[0,x_1]$ e si iteri il processo per \textit{N} volte: si tratta di un processo ricorsivo con memoria del passato.
				Essendo la distribuzione di probabilità uniforme risulta ovvio come $<x>=\frac{1}{2}$ quindi è possibile riscalare il tutto con una variabile $y\rightarrow\frac{y}{2}$
				Definita la densità $\rho$ del sistema si può scrivere:
				\begin{equation*}
					\begin{split}
						\rho_{N+1}\left(\frac{y}{2}\right)\frac{dy}{2}&=\rho_N(y)dy\\
						\Rightarrow\lim_{N\to\infty}\rho_N(y)&\propto\frac{1}{y}
					\end{split}
				\end{equation*}
				Il risultato è una legge a potenza con $\alpha=-1$, quindi \textit{non normalizzabile} in quanto l'integrale diverge.
				Il sistema ha un effetto di memoria assoluta: una volta tagliato il segmento non è possibile riattaccarlo.
				Se il segmento non venisse tagliato si otterrebbe un andamento a potenza con $\alpha\geq 1$ e risulterebbe pertanto normalizzabile.
				Un'utile applicazione dei modelli di Markov si trova nel linguaggio (verbi) e in biologia (DNA).
			\subsection{Penney's game}
				Si prenda una moneta e la si lanci all'infinito.
				Si vuole scommettere con un'altra persona su una terna di uscite consecutive dai lanci e ci si chiede come si possa vincere più facilmente.
				Analizzando attentamente il problema si può notare come l'uscita delle sequenze non sia casuale ma segua un percorso ben preciso: l'unica sequenza casuale è quella data dalle prime tre uscite.
							
				\begin{figure}
					\centering
					\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        
					\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
					%uncomment if require: \path (0,180); %set diagram left start at 0, and has height of 180

					%Straight Lines [id:da6422687951145654] 
					\draw    (44,65) -- (85,32) -- (90,28) ;
					\draw [shift={(91,27)}, rotate = 501.04] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da7705936405819056] 
					\draw    (94,137) -- (40.53,92.28) ;
					\draw [shift={(39,91)}, rotate = 399.90999999999997] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da6670914365776015] 
					\draw    (120,90) -- (120,121) ;
					\draw [shift={(120,123)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da5676959026170221] 
					\draw    (119,32) -- (119,63) ;
					\draw [shift={(119,65)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da6639824453006449] 
					\draw    (137,22) -- (172,22) ;
					\draw [shift={(174,22)}, rotate = 180] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da07868476619961107] 
					\draw    (179,138) -- (140,138) ;
					\draw [shift={(138,138)}, rotate = 360] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da2178688499902217] 
					\draw    (178,77) -- (139,77) ;
					\draw [shift={(137,77)}, rotate = 360] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da6042868291237622] 
					\draw    (139,84) -- (175,84) ;
					\draw [shift={(177,84)}, rotate = 180] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da3451851868864586] 
					\draw    (218,21) -- (274.42,64.77) ;
					\draw [shift={(276,66)}, rotate = 217.81] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da5761550996457687] 
					\draw    (275,95) -- (223.51,139.69) ;
					\draw [shift={(222,141)}, rotate = 319.03999999999996] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da9885549593906195] 
					\draw    (197,128) -- (197,89) ;
					\draw [shift={(197,87)}, rotate = 450] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da6638039461895064] 
					\draw    (198,70) -- (198,31) ;
					\draw [shift={(198,29)}, rotate = 450] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Curve Lines [id:da8915331259906252] 
					\draw    (100,130) .. controls (60.42,98.3) and (61.96,64.68) .. (100.81,34.9) ;
					\draw [shift={(102,34)}, rotate = 503.13] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Curve Lines [id:da07525012510942974] 
					\draw    (213,29) .. controls (259.53,59.69) and (261.96,88.42) .. (219.31,127.8) ;
					\draw [shift={(218,129)}, rotate = 317.73] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;

					% Text Node
					\draw (20,70) node [anchor=north west][inner sep=0.75pt]   [align=left] {HHH};
					% Text Node
					\draw (100,15) node [anchor=north west][inner sep=0.75pt]   [align=left] {HHT};
					% Text Node
					\draw (100,70) node [anchor=north west][inner sep=0.75pt]   [align=left] {HTH};
					% Text Node
					\draw (100,130) node [anchor=north west][inner sep=0.75pt]   [align=left] {THH};
					% Text Node
					\draw (180,70) node [anchor=north west][inner sep=0.75pt]   [align=left] {THT};
					% Text Node
					\draw (260,70) node [anchor=north west][inner sep=0.75pt]   [align=left] {TTT};
					% Text Node
					\draw (180,15) node [anchor=north west][inner sep=0.75pt]   [align=left] {HTT};
					% Text Node
					\draw (180,130) node [anchor=north west][inner sep=0.75pt]   [align=left] {TTH};

					\end{tikzpicture}
					\caption{Schema del gioco di Penney}
					\label{Penney's scheme}
				\end{figure}
				In questo modo risulta abbastanza semplice fregare l' avversario: facendolo scegliere per primo, è sempre possibile scegliere una sequenza più probabile della sua.\\
				Eseguendo i calcoli si nota subito come la probabilità stazionaria del sistema sia data da $\left(\frac{1}{2}\right)^3=\frac{1}{8}=12.5\%$.
				Scegliendo per secondi si vince sempre a meno che la sequenza dell'avversario non esca dai primi tre lanci, quindi eseguendo i calcoli sulle probabilità si ottiene la seguente tabella:
				\begin{center}
					\begin{tabular}{ |c|c|c|c| } 
						\hline
						1st player's choice& 2nd player's choice & 2nd player's winning chance\\
						\hline
						\emph{HH}H & \textbf{T}\emph{HH} & 87.5\% \\
						\emph{HH}T & \textbf{T}\emph{HH} & 75.0\% \\
						\emph{HT}H & \textbf{H}\emph{HT} & 66.7\% \\
						\emph{HT}T & \textbf{H}\emph{HT} & 66.7\% \\
						\emph{TH}H & \textbf{T}\emph{TH} & 66.7\% \\
						\emph{TH}T & \textbf{T}\emph{TH} & 66.7\% \\
						\emph{TT}H & \textbf{H}\emph{TT} & 75.0\% \\
						\emph{TT}T & \textbf{H}\emph{TT} & 87.5\% \\
						\hline
					\end{tabular}
				\end{center}
				Nel primo e nell'ultimo caso si nota facilmente come la vittoria sia certa ammesso che non esca la tripletta scelta dal giocatore 1.
				Essendo la probabilità stazionaria $\frac{1}{2}$, $P_{1,8}=1-\left(\frac{1}{2}\right)^3=\frac{7}{8}$.\\
				Nel secondo e nel penutlimo caso si può ragionare in modo analogo al caso precedente, ottenendo $P_{2,7}=1-\left(\frac{1}{2}\right)^2=\frac{3}{4}$.\\
				In tutti gli altri casi la probabilità è data da $P_{3,4,5,6}=\frac{1}{2}+\frac{1}{2}P(player1)\ldots=\frac{1}{2}\sum_{n=0}^\infty\left(\frac{1}{4}\right)^n=\frac{2}{3}$.

	\chapter{Modelli di trasporto} %CAPITOLO 3
		\section{Teoria}
			Consideriamo due punti ($A$ e $B$) di un generico spazio e colleghiamoli con un canale immaginario, facendo riferimento alla Fig.1, possiamo definire il flusso $\Phi_{A \rightarrow B}$ di una quantità fisica trasportata nell'unità di tempo tra i due punti.
			\begin{figure}[ht!]
					\centering
					\begin{tikzpicture}
					\Vertex[label=$A$, color=white]{A}
					\Vertex[label=$B$,color=white,x=2.5,y=0]{B}
					\Edge[Direct, lw=0.5pt, label=$\Phi_{A \rightarrow B}$](A)(B)
				\end{tikzpicture}
					\caption{}
			\end{figure}
			Definiamo $V_{A/B}$ una certa proprietà del nodo $A/B$, questa proprietà ne definisce lo stato. Possiamo quindi scrivere una sorta di legge di Ohm per la situazione descritta 
			\begin{equation*}
					\Phi_{A \rightarrow B} \ R = V_A - V_B
			\end{equation*} dove $R$ è una proprietà del link (ad es. la portanza di una strada ma anche la probabilità di transizione).
			Osserviamo che è di notevole importanza la dimensione del link ($L$) in quanto se attraversiamo il link abbiamo un flusso $\Phi$, di conseguenza la capacità del sistema di trasporto richiede $\Phi L$ di “veicoli".			
			\begin{figure}[ht!]
					\centering
					\begin{tikzpicture}
						\Vertex[label=$A$, color=white]{A}
						\Vertex[label=$B$,color=white,x=1,y=1]{B}
						\Vertex[label=$C$,color=white,x=-1,y=1]{C}
						\Vertex[label=$D$,color=white,x=0,y=1]{D}
						\Vertex[label=$S$,color=white,x=0,y=-1]{S}
						\Edge[Direct, lw=0.5pt](A)(B)
						\Edge[Direct, lw=0.5pt](A)(C)
						\Edge[Direct, lw=0.5pt](A)(D)
						\Edge[Direct, lw=0.5pt](S)(A)
					\end{tikzpicture}
					\caption{}
			\end{figure}
		
		\section{Esempi}

		
	
	
	\chapter{Teoria del controllo} %CAPITOLO 4
		\section{Approccio generale}
			La \emph{teoria del controllo} è quella branca della fisica che studia come controllare i sistemi dinamici.
			L'obiettivo principale è quello di creare un \emph{controllo}, ossia un modello/algoritmo, in grado di portare un sistema dinamico in un determinato stato dato uno stato iniziale (in input).
			\begin{definition}
				Il modello è detto ottimale quando si è raggiunto un buon livello di stabilità, minimizzando i riratdi e gli errori.
			\end{definition}
			Il dispositivo che gestisce il sistema dinamico è detto \emph{controllore} e va selezionato accuratamente in base alle richieste del sistema da gestire.
			Formalmente il controllo viene immesso nel sistema attraverso una forzante che, aggiunta alla lagrangiana, permette lo studio e l'ottimizzazione del problema.
			Per maggiori informazioni sulla meccanica analitica è possibile consultare gli appunti delle lezioni al link \url{https://github.com/Grufoony/Fisica_UNIBO/blob/main/Appunti_meccanica_analitica.pdf}.
		
		\section{Applicazioni biologiche}
			Si supponga ora di voler studiare un sistema biologico quale, ad esempio, il cuore umano.
			\begin{figure}[H]
				\centering
				\begin{tikzpicture}
					\begin{axis}[
						xmin = 0, xmax = 20,
						ymin = -3, ymax = 3,
						samples = 200,
						smooth,
						thick,
						xlabel = {$t$},
						ylabel = {$V(t)$},]
						\addplot[
							domain = 0:20,
						] {sin(2*deg(x+pi))-2*sin(deg(x+pi))};
					\end{axis}
				\end{tikzpicture}
				\caption{\emph{Stilizzazione del battito cardiaco.}}
				\label{figure:battito_cardiaco}
			\end{figure}
			Il battito cardiaco stilizzato in Fig \ref{figure:battito_cardiaco} suggerisce un modello in cui:
			\begin{itemize}
				\item il sistema abbia un equilibrio (al quale ritorna periodicamente)
				\item esiste una soglia trigger di un'onda 
			\end{itemize}
			L'idea è ridurre la cellula cardiaca ad un sistema complesso a due variabile, $x$ per la lunghezza della fibra e $b$ per lo stimolo elettrochimico da associare ad essa (controllo elettrico).
			Il modello di Zeeman è rappresentato dal sistema
			\begin{equation}
				\begin{cases}
					\epsilon\frac{dx}{dt}=&-\left(x^3-Tx+b\right)\\
					\frac{db}{dt}=&x-x_{0}
				\end{cases}
			\end{equation}
			in cui la prima equazione ricorda l'equazione logistica (Eq. \ref{equation:equazione_logistica}).
			Il fattore infinitesimo $\epsilon$ garantisce una scala di evoluzione rapida.
			\begin{figure}[H]
				\centering
				\begin{tikzpicture}
					\begin{axis}[
						xmin = -5, xmax = 5,
						ymin = -5, ymax = 5,
						samples = 200,
						smooth,
						thick,
						xlabel = {$x$},
						ylabel = {$b$},]
						\addplot[domain = -5:5] {-x^3+3*x};
						\addplot [only marks,mark=*,nodes near coords=A] coordinates { (-1,-2) };
						\addplot [only marks,mark=*,nodes near coords=B] coordinates { (1,2) };
						\end{axis}
				\end{tikzpicture}
				\caption{\emph{Nullclina.}}
				\label{figure:nullcline}
			\end{figure}
			L'equilibrio stabile si ha sulla \emph{nullclina} $\frac{dx}{dt}=0$, quindi per $x=x_{0}$ e $b=-x^3+Tx$, il cui grafico è riportato in Fig. \ref{figure:nullcline}
			I punti $A$ e $B$ sono ovviamente i punti critici del sistema: la parte di curva compresa tra i due punti non è esplorabile in quanto da $B$ è solo possibile ricadere sul ramo di $A$ e viceversa.
			Questa è l'\emph{idea della catastrofe} di Zeeman, ove per $A<b<B$ perdo l'invertibilità del sistema.
			Se si è in presenza di uno stimolo ad onda quadra che riesce a spostare il sistema oltre il punto $B$ (facendolo quindi ricadere su $A$) si ha la contrazione (sistole e diastole, vedi Fig. \ref{figure:sistole_diastole})
			\begin{figure}[H]
				\centering
				\begin{tikzpicture}
					\begin{axis}[
						xmin=-3, xmax=3,
						ymin=-3, ymax=3,
						thick,
						]
						\draw[black] \pgfextra{
						\pgfpathellipse{\pgfplotspointaxisxy{0}{0}}
						{\pgfplotspointaxisdirectionxy{0}{2}}
						{\pgfplotspointaxisdirectionxy{1}{-1}}
						};
						\addplot [only marks,mark=*,nodes near coords=A] coordinates { (-0.6,2.2) };
						\addplot [only marks,mark=*,nodes near coords=B] coordinates { (0.6,-2.2) };
						\end{axis}
				\end{tikzpicture}
				\caption{\emph{Sistole ($A\to B$) e disatole ($B\to A$).}}
				\label{figure:sistole_diastole}
			\end{figure}
			Volendo ora dimostrare formalmente la stabilità del punto di equilibrio $(x_0,b_0)$ è conveniente lavorare in un intorno di esso:
			\begin{equation*}
				\begin{split}
					\Delta x =& x-x_0\\
					\Delta b =& b-b_0\\
				\end{split}
			\end{equation*}
			Linearizzando il sistema
			\begin{equation*}
				\begin{cases}
					\epsilon\frac{d\Delta x}{dt}=&-\left(3x_0^2-T\right)\Delta x-\Delta b\\
					\frac{d\Delta b}{dt}=&\Delta x
				\end{cases}
			\end{equation*}
			ei ottiene la matrice
			\begin{equation*}
				\left(
				\begin{matrix}
					\frac{\left(-3x_0^2+T\right)}{\epsilon} & -\frac{1}{\epsilon}\\
					1 & 0 
				\end{matrix}
				\right)
			\end{equation*}
			con determinante $\frac{1}{\epsilon}>0$.
			Data la presenza di un quadrato la stabilità non dipenderà dal segno di $x_0$ quanto dal suo modulo.
			Il determinante positivo implica autovalori entrambi positivi o entrambi negativi: si avranno autovalori positivi, quindi un punto instabile, se la traccia è positiva e viceversa.
			Si assuma ora di voler introdurre una funzione periodica $x^+(t)$ di periodo sufficiente per effettuare il ``salto''.
			\begin{equation*}
				\begin{cases}
					\epsilon\frac{dx}{dt}=&-\left(x^3-Tx+b\right)\\
					\frac{db}{dt}=&x-x^+(t)
				\end{cases}
			\end{equation*}
			Ora è possibile accoppiare due cellule cardiache come segue
			\begin{equation*}
				\begin{cases}
					\epsilon\frac{dx}{dt}=&-\left(x^3-Tx+b\right)\\
					\frac{db}{dt}=&x-y\\
					\epsilon\frac{dy}{dt}=&-\left(y^3-Ty+b'\right)\\
					\frac{db'}{dt}=&y-x
				\end{cases}
			\end{equation*}
			con $x(0)\simeq x_0$ e $y(0)\simeq x_1$ punti di equilibrio.
			Per fare in modo che il sistema sostenga l'onda (senza il bisogno di uno stimolo esterno) è necessario un accoppiamento in controfase, ossia quando la cellula $x$ è in contrazione la $y$ è in dilatazione e viceversa.
			Creando una catena di questi oggetti è possibile quindi generare un fenomeno d'onda.

		\section{Esempi}
			\subsection{Pendolo rovesciato}
				L'esempio più classico di sistema controllabile è dato dal pendolo rovesciato.
				\begin{figure}
					\centering
						\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        
					\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
						%uncomment if require: \path (0,300); %set diagram left start at 0, and has height of 300
		
						%Shape: Axis 2D [id:dp3368840244616125] 
						\draw  (85,261) -- (358,261)(112.3,54) -- (112.3,284) (351,256) -- (358,261) -- (351,266) (107.3,61) -- (112.3,54) -- (117.3,61)  ;
						%Straight Lines [id:da9817096320288043] 
						\draw    (301,111) -- (210,261) ;
						%Straight Lines [id:da06758975743465334] 
						\draw  [dash pattern={on 4.5pt off 4.5pt}]  (210,109) -- (210,261) ;
						%Straight Lines [id:da2034168201391482] 
						\draw    (210,209) -- (231.29,221.96) ;
						\draw [shift={(233,223)}, rotate = 211.33] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
						%Shape: Circle [id:dp9770248165887236] 
						\draw  [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ,fill opacity=1 ] (204.5,261) .. controls (204.5,257.96) and (206.96,255.5) .. (210,255.5) .. controls (213.04,255.5) and (215.5,257.96) .. (215.5,261) .. controls (215.5,264.04) and (213.04,266.5) .. (210,266.5) .. controls (206.96,266.5) and (204.5,264.04) .. (204.5,261) -- cycle ;
						%Shape: Circle [id:dp8368022401757067] 
						\draw  [fill={rgb, 255:red, 0; green, 0; blue, 0 }  ,fill opacity=1 ] (295.5,111) .. controls (295.5,107.96) and (297.96,105.5) .. (301,105.5) .. controls (304.04,105.5) and (306.5,107.96) .. (306.5,111) .. controls (306.5,114.04) and (304.04,116.5) .. (301,116.5) .. controls (297.96,116.5) and (295.5,114.04) .. (295.5,111) -- cycle ;
		
						% Text Node
						\draw (122,127) node [anchor=north west][inner sep=0.75pt]   [align=left] {$ $};
						% Text Node
						\draw (222,190) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle \theta $};
						% Text Node
						\draw (201,268) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle x_{C}$};
						% Text Node
						\draw (308,88) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle x_{O}$};
						\end{tikzpicture}
					\caption{Pendolo rovesciato}
					\label{figure:pendolo}
				\end{figure}
				Siano $x_{C}(t)$ la coordinata del controllore, $x_{O}(t)$ la coordinata del pendolo di lunghezza $l$ e $\theta$ l'angolo formato da esso con la verticale.
				Utilizzando la meccanica lagrangiana:
				\begin{equation*}
					\begin{cases}
						x_{O}=x_{C}+l\sin\theta\\
						y_{O}=l\cos\theta
					\end{cases}
				\end{equation*}
				\begin{equation*}
					\begin{cases}
						\dot{x}_O=\dot{x}_{C}+l\dot{\theta}\cos\theta\\
						\dot{y}_{O}=l\dot{\theta}\sin\theta
					\end{cases}
				\end{equation*}
				La lagrangiana del sistema si può scrivere come:
				\begin{equation*}
					\mathcal{L}=\frac{m}{2}\left( \left( \dot{x}_{C}+l\dot{\theta}\cos\theta \right)^2 + l^2\dot{\theta}^2\sin^2\theta \right) - mgl\cos\theta \simeq \frac{m}{2}\left( l^2\dot{\theta}^2 + 2\dot{x}_{C}l\dot{\theta}\cos\theta \right) - mgl\cos\theta
				\end{equation*}
				alle piccole oscillazioni ($\theta\simeq 0$ e $mgl\cos\theta\simeq -mgl\frac{\theta^2}{2}$):
				\begin{equation*}
					\mathcal{L}_{PO}=\frac{m}{2}\left( l^2\dot{\theta}^2 + 2\dot{x}_{C}l\dot{\theta} \right) + mgl\frac{\theta^2}{2}
				\end{equation*}
				L'equazione del moto risulta infine:
				\begin{equation}
					\ddot{\theta}=\frac{g}{l}\theta - \frac{\ddot{x}_C}{l}
				\end{equation}
				Riconosciuta la forzante, per semplicità si pone $\ddot{x}_C=\pm a(t)$ costante.
				La soluzione non è omogenea:
				\begin{equation*}
					\theta(t)=\left( \theta_{0} -\frac{a(t)}{g} \right)\cosh\omega t + \frac{\dot{\theta}_0}{\omega}\sinh\omega t +\frac{a(t)}{g}
				\end{equation*}
				Assumendo ora $\theta_0\simeq 0$ e $\dot{\theta}_0\neq 0$ e che il pendolo si stabilizzi in un tempo $T$ si ha la soluzione stabile:
				\begin{equation*}
					\theta(T)=C\cosh\omega T + C\sinh\omega T \simeq Ce^{-\omega T}
				\end{equation*}
				Si può ora ricavare la condizione richiesta:
				\begin{equation}
					C=\theta(T)=-\frac{\dot{\theta}(T)}{\omega}
				\end{equation}
				Andando a imporla si ottiene:
				\begin{equation*}
					-\frac{a}{g}\cosh\omega T + \frac{\dot{\theta}(T)}{\omega}\sinh\omega T + \frac{a}{g} = \frac{a}{g}\sinh\omega T - \frac{\dot{\theta}(T)}{\omega}\cosh\omega T
				\end{equation*}
				Da cui si può ricavare il periodo di stabilità:
				\begin{equation}
					T=\frac{1}{\omega}\ln\frac{\frac{a}{g}}{\frac{a}{g}-\frac{\dot{\theta}(T)}{\omega}}
				\end{equation}
				Un'osservazione importante riguarda la \emph{condizione critica} del sistema, ove esso non risulta più controllabile, che si ha quando $\dot{\theta}_0=\frac{a\omega}{g}$.
			\subsection{Marriage Model/Modello relazionale}
				Si supponga ora di voler controllare una relazione con un'altra persona, che tipo di relazione conviene studiare?
				La scrittrice Anna Karenina sembra fornire una soluzione al problema, constatando che \emph{tutte le relazioni felici sono uguali ma ogni relazione infelice lo è a modo suo}.
				Sia ora $x(t)$ il grado di felicità nella relazione che, per semplicità si assume positivo ($x(t)\in\mathbb{R}^{+}$) in accordo con l'ipotesi della Karenina.
				L'equazione che descrive la relazione sarà del tipo:
				\begin{equation}
					\dot{x}=-rx(t)+ac(t)
				\end{equation}
				in cui riconosciamo la funzione \emph{costo} $c(t)$ della relazione (ove per costo si intende uscire a cena, fare un regalo, ecc...),il parametro $r$ (quanto la felicità tenda a diminuire) e il parametro $a$ (amplificazione del costo).
				La relazione giungerà al termine una volta arrivati ad un valore minimo della felicità, che verrà denotato come $x_{m}$.
				\\Per rafforzare il modello si introducono ora due potenziali:
				\begin{itemize}
					\item $U(x)$, \emph{utility potential}, il quale indica quanto funziona la coppia.
						Esso deve essere tale che $U'(x)>0$ ma $U''(x)<0$, in quanto troppa felicità tende a saturare la relazione;
					\item $D(c)$, \emph{disutility potential}, il quale tiene conto dello sforzo eseguito.
						Più il costo del mantenimento della relazione aumenta, più essa tende a fallire (non ne vale la pena).
						Ovviamente $D(c)$ deve avere un minimo, dato che esiste uno sforzo considerato accettabile per mantenere la relazione;
				\end{itemize}
				Si può ora definire il funzionale di soddisfazione come:
				\begin{equation*}
					W(c)=\int_{0}^{\infty}e^{-\lambda t}\left[U\left(x(t)\right)-D\left(c(t)\right)\right]dt
				\end{equation*}
				dove il coefficiente $\lambda^{-1}$ rappresenta la scala di memoria del sistema.
				\\Per ottimizzare il problema si deve avere
				\begin{equation*}
					\delta\dot{x}=-r\delta x+a\delta c
				\end{equation*}
				e quindi la variazione infinitesima del funzionale
				\begin{equation*}
					\delta W(c)=\int_{0}^{\infty}e^{-\lambda t}\left[U'(x)'\delta x-D'(c)\delta c\right]dt=\int_{0}^{\infty}e^{-\lambda t}\left[U'(x)'\delta x-D'(c)\frac{\delta\dot{x}+r\delta x}{a}\right]dt
				\end{equation*}
				Integrando per parti:
				\begin{equation*}
					-\int e^{-\lambda t}D'(c)\frac{\delta\dot{x}}{a}dt=-\left[ e^{-\lambda t}D'(c)\frac{\delta x}{a} \right]_{0}^{\infty} + \int_{0}^{\infty}\frac{d}{dt}\left[\frac{e^{-\lambda t}D'(c)\delta x}{a}\right]dt
				\end{equation*}
				e quindi
				\begin{equation*}
					\delta W=\int_{0}^{\infty}\left\{ e^{-\lambda t}U'(x)+\frac{d}{dt}\left[\frac{e^{-\lambda t}D'(c)}{a}\right]-\frac{e^{-\lambda t}D'(c)r}{a} \right\}\delta xdt
				\end{equation*}
				Essendo $\delta x$ arbitrario
				\begin{equation*}
					D''\left(c(t)\right)\frac{dc}{dt}=(r+\lambda)D'(c)-aU'(x)
				\end{equation*}
				\\Si assumano ora, per esempio, i seguenti potenziali
				\begin{equation}
					\begin{cases}
						U(x)=U_{\infty}\left(1-e^{-\alpha x}\right)\\
						D(c)=c\left(c-2c_{0}\right)
					\end{cases}
				\end{equation}
				che forniscono il seguente sistema (equilibrio instabile):
				\begin{equation}
					\begin{cases}
						\dot{x}=-rx+ac\\
						\dot{c}=(r+\lambda)(c-c_{0})-\alpha\frac{e^{-\alpha x}}{2}
					\end{cases}
				\end{equation}
				\begin{figure}[H]
					\centering
					\tikzset{every picture/.style={line width=0.75pt}} %set default line width to 0.75pt        

					\begin{tikzpicture}[x=0.75pt,y=0.75pt,yscale=-1,xscale=1]
					%uncomment if require: \path (0,341); %set diagram left start at 0, and has height of 341

					%Shape: Axis 2D [id:dp3368840244616125] 
					\draw  (57,269.8) -- (396,269.8)(90.9,16) -- (90.9,298) (389,264.8) -- (396,269.8) -- (389,274.8) (85.9,23) -- (90.9,16) -- (95.9,23)  ;
					%Straight Lines [id:da3652200107960064] 
					\draw  [dash pattern={on 0.84pt off 2.51pt}]  (91,40) -- (400,41) ;
					%Straight Lines [id:da5006530252551029] 
					\draw  [dash pattern={on 0.84pt off 2.51pt}]  (120,40) -- (121,271) ;
					%Straight Lines [id:da8026254906595234] 
					\draw    (132,51) -- (230.59,149.59) ;
					\draw [shift={(232,151)}, rotate = 225] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da13202518334193436] 
					\draw    (232,151) -- (329.59,52.42) ;
					\draw [shift={(331,51)}, rotate = 134.71] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da12999604842472334] 
					\draw    (232,151) -- (132.42,249.59) ;
					\draw [shift={(131,251)}, rotate = 315.29] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da6286757540841101] 
					\draw    (329,251) -- (233.39,152.44) ;
					\draw [shift={(232,151)}, rotate = 45.87] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da6186409744974593] 
					\draw  [dash pattern={on 0.84pt off 2.51pt}]  (331,90) -- (331,218) ;
					\draw [shift={(331,220)}, rotate = 270] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Straight Lines [id:da17147537985002903] 
					\draw  [dash pattern={on 0.84pt off 2.51pt}]  (131,219) -- (131.98,92) ;
					\draw [shift={(132,90)}, rotate = 90.44] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Curve Lines [id:da625223071951815] 
					\draw    (132,90) .. controls (191.7,96.97) and (225.66,180.16) .. (132.42,218.43) ;
					\draw [shift={(131,219)}, rotate = 338.2] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Curve Lines [id:da4439025038344766] 
					\draw    (331,220) .. controls (245.43,195.12) and (252.92,96) .. (329.84,90.08) ;
					\draw [shift={(331,90)}, rotate = 176.33] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Curve Lines [id:da7044254609861651] 
					\draw    (170,51) .. controls (170,117.33) and (294.47,110.15) .. (298.9,54.7) ;
					\draw [shift={(299,53)}, rotate = 92.01] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;
					%Curve Lines [id:da4584745322280377] 
					\draw    (302,250) .. controls (302,182.34) and (163.4,181.01) .. (161.03,248.97) ;
					\draw [shift={(161,250)}, rotate = 270.83] [color={rgb, 255:red, 0; green, 0; blue, 0 }  ][line width=0.75]    (10.93,-3.29) .. controls (6.95,-1.4) and (3.31,-0.3) .. (0,0) .. controls (3.31,0.3) and (6.95,1.4) .. (10.93,3.29)   ;

					% Text Node
					\draw (122,127) node [anchor=north west][inner sep=0.75pt]   [align=left] {$ $};
					% Text Node
					\draw (44,169) node [anchor=north west][inner sep=0.75pt]  [rotate=-270] [align=left] {costo};
					% Text Node
					\draw (203,285) node [anchor=north west][inner sep=0.75pt]   [align=left] {felicità};
					% Text Node
					\draw (47,29) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle c_{m}{}_{a}{}_{x}$};
					% Text Node
					\draw (112,275) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle x_{m}$};
					% Text Node
					\draw (333,73) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle A'$};
					% Text Node
					\draw (338,209) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle A$};
					% Text Node
					\draw (123,223) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle B'$};
					% Text Node
					\draw (126,67) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle B$};
					% Text Node
					\draw (190,139) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle \gamma _{B}$};
					% Text Node
					\draw (245,138) node [anchor=north west][inner sep=0.75pt]   [align=left] {$\displaystyle \gamma _{A}$};


					\end{tikzpicture}
					\caption{Orbite relazionali.}
					\label{figure:orbite}
				\end{figure}
				Le orbite risultanti sono riportate in Fig.(\ref{figure:orbite}), dove si possono distinguere due strategie:
				\begin{itemize}
					\item STRATEGIA A: si segue un'orbita $\gamma_{A}$ dai punti $A\rightarrow A'$ poi si fa una decrescita discontinua lungo una $c(t)$ da $A'\rightarrow A$.
						Sostanzialmente si spende molto per la relazione (nei termini visti in precedenza) poi, una volta divenuto intollerabile il costo, si fa una bella litigata e si ricomincia il ciclo;
					\item STRATEGIA B: si segue un'orbita $\gamma_{B}$ dai punti $B\rightarrow B'$ poi si fa una crescita discontinua lungo una $c(t)$ da $B'\rightarrow B$.
						In questo caso si lascia andare la relazione senza apportare sufficiente sforzo poi, ad un passo dalla rottura, si rimedia il tutto con un gesto importante (alto costo) per ristabilire l'orbita.
				\end{itemize}
				In entrambi i casi bisogna, tuttavia, prestare parecchia attenzione una volta raggiunti i minimi: se lungo la $\gamma_{A}$ si fa una litigata troppo pesante o lungo la $\gamma_{B}$ si trascura troppo la relazione, si rischia di finire fuori orbita (quindi fuori equilibrio) e far così fallire la relazione (il che è \emph{no buono}, n.d.r.).
			\subsection{Modello di Fitzhugh-Nagumo}
				Un'altra applicazione biologica è rappresentata dal modello per il neurone di Fitzhugh-Nagumo, basato sull'oscillatore di Var der Pol.
				Definite $x$ potenziale di membrana e $w$ la corrente, il modello consiste nelle equazioni differenziali:
				\begin{equation}
					\begin{cases}
						\frac{dx}{dt}=&-\frac{x^3}{3}+x-w+I\\
						\frac{dw}{dt}=&\frac{1}{\tau}\left(x-bw+a\right)
					\end{cases}
					\label{equation:fitzhugh_nagumo}
				\end{equation}
				con $\frac{1}{\tau}<<1$ in modo da avere $x$ variabile veloce e $w$ lenta.
				Anche in questo caso si ottiene una nullclina simile a quella rappresentata in Fig. \ref{figure:nullcline}.\\
				La stabilità all'equilibrio è data da:
				\begin{equation*}
					\begin{cases}
						w=&-\frac{x^3}{3}+x+I\\
						w=&\frac{x+a}{b}
					\end{cases}
				\end{equation*}
				Si può verificare come esiste (e sia unico) un punto di equilibrio stabile $P$ quindi, assumendo di aver trovato la risoluzione al sistema, è possibile linearizzare il campo
				\begin{equation*}
					\begin{cases}
						\delta\dot{x}=&\left(1-x_P^2\right)\delta x - \delta w\\
						\delta\dot{w}=&\frac{1}{\tau}\delta x -\frac{b}{\tau}\delta w
					\end{cases}
				\end{equation*}
				riscrivibile come matrice
				\begin{equation*}
					\left(
					\begin{matrix}
						1-x_P^2 & -1\\
						\frac{1}{\tau} & -\frac{n}{\tau}
					\end{matrix}
					\right)
				\end{equation*}
				che ha determinante $-\frac{b}{\tau}\left(1-x_P^2\right)+\frac{1}{\tau}$.
				La stabilità si ha per un modulo sufficientemente grande di $x_P$ (anche se $x_P\to 0$ al crescere di $I$) mentre l'instabilità si ha per $b<1$.
				Lo stimolo è rappresentato da una variazione della $I$ che, se abbastanza rapida, permette di percorrere la nullclina.\\
				Il sistema è non caotico ma con derivate di ordine diverso (Stiff).
				Si assuma $I(t)=\Delta x\delta(t)$, allora $x(0^+)=x_0+\Delta x$ se $x(0^-)=x_0$, quindi se $\Delta x$ supera una determinata soglia si ha una grande fluttuazione.
				Per $(x,w)$ abbastanza grandi è possibile definire la funzione di Ljapunov
				\begin{equation}
					H=\frac{1}{2}\left(w^2+\frac{x^2}{\tau}\right)
				\end{equation}
				costante che rappresenta un'ellisse.
				La derivata della funzione di Ljapunov è negativa quindi la dinamica non è espansiva e il sistema non può esplodere: si arriva così ad una \emph{biforcazione di Hopf}, ossia si parte da una situazione attrattiva rispetto al punto fisso e, passando attraverso una situazione repulsiva (grazie ad un parametro) si arriva ad un ciclo limite, quale traiettoria periodica di un attrattore dinamico.

	\chapter{Altre applicazioni} %CAPITOLO 5
		\section{Fisica della città}
			Un'applicazione interessante dei sistemi complessi riguarda l'ambito urbano (e sociale).
			Uno dei primi problemi affrontati storicamente è il problema del traffico.
			Tante auto si muovono su un network, ognuna delle quali tende a mantenere una velocità ottimale in base alla macchina che la precede: questa dinamica viola la terza legge di Newton in quanto non è detto che la macchina che sta dietro influenzi quella davanti.
			Le \emph{onde di traffico} si vengono a creare a causa dei tempi di reazione degli automobilisti (mai istantanei).
			Nonostante la creazione di queste onde, il flusso di auto sulla strada rimane costante.\\
			Osservando dati sperimentali riguardanti le velocità si nota un appiattimento ad alte densità della curva, dunque il tutto satura ad una velocità media fissa.
			Posto $j$ come indice di un veicolo, un modello stile Newton obbedisce a:
			\begin{equation}
				\begin{cases}
					\dot{s}_j=&v_j\\
					\dot{v}_j=&-\beta\left(v_j-v_{opt}\left(s_{j-1}-s_j\right)\right)
				\end{cases}
				\label{equation:traffic}
			\end{equation}
			Il parametro $\beta$ è proporzionale all'accelerazione ma l'equazione di secondo ordine implica un'equazione di prim'ordine con ritardo (tempo di reazione).
			Se $\beta$ è molto basso allora si creano onde solitoniche  e ogni plateau dell'onda corrisponde ad un equilibrio del sistema.
			Questo sistema statistico crea un equilibrio dinamico, perchè dinamicamente si ha qualcosa che si propaga nel sistema, che contiene un equilibrio dove le auto vanno veloce e uno dove le auto vanno lente.
			Quando il sistema non riesce a mantenere l'equilibrio globale, si formano degli equilibri a livello locale.
			Normalmente, infatti, si osserva che aumentando il numero di auto in una strada il flusso stesso aumenti fino ad arrivare ad una situazione di instabilità: esiste quindi un valore critico di densità superato il quale il flusso inizia a diminuire e il sistema non riesce più a rispondere al flusso immesso, dando luogo al flusso stop\&go e creando l'onda solitonica.\\
			Un \emph{fundamental diagram} è un concetto molto utilizzato nelle reti di trasporto: in questo il punto critico di densità risulta un massimo.
			Tuttavia, il meccanismo di stop\&go si innesca molto prima che il sistema giunga a questo massimo
			La geometria del sistema è fondamentale, in quanto descrive come esso smorzi/sostenga le oscillazioni delle sorgenti.
			In autostrada, ad esempio, le congestioni (variazioni della velocità media) si hanno nei punti di immissione, poi si propagano come onde solitone.
			Vi è inoltre un'alta sensibilità alle fluttuazioni, in quanto ogni persona guida in modo differente, la cui ampiezza aumenta con la densità seguendo un regime poissoniano (maggiore il valore medio maggiori le fluttuazioni).
			Per arrivare al flusso ottimale bisogna diminuire la fluttuazioni, quindi \emph{raffreddare} il sistema (auto a guida autonoma).\\
			Una proposta di Tom Tom utilizza la velocità media come osservabile macroscopico: la velocità media delle auto in città è tuttavia molto bassa, a causa delle soste forzate, mentre la mobilità ciclistica risulta decisamente più alta.
			\subsection{Modelli di traffico}
				Si consideri ora un network in cui ogni nodo è o sorgente o destinazione (tipico di aeroporti e stazioni ferroviarie).
				Senza considerare la dinamica del singolo veicolo, si assuma poi che ogni link riesca a trasportare, quindi che abbia capacità infinita (cosa non assumibile nel caso delle automobili).
				Cosa accade agli incroci?\\
				Se si assumono nodi a capacità finita allora la congestione si ha quando un nodo diminuisce la capacità di creare trasporto.
				Sia $n_i$ il numero di agenti presenti nel nodo $i$.
				Una volta fornito un peso al link la domanda di mobilità dipenderà da $n$ e dal flusso tra i nodi $i$ e $j$.
				Si può calcolare la probabilità di transizione $i\to j$ come $\pi_{ij}n_i$: questa risulta proporzionale al numero di agenti, quindi maggiore è $n_i$ maggiore è la probabilità che questi si allontanino dal nodo $i$.
				Fisicamente questo ricorda un reticolo cristallino con elettroni ai nodi: un elettrone può transire da un nodo ad un altro solo se la destinazione è vuota.\\
				Fondamentale ora introdurre una legge di continuità (ossia una corrente), in quanto un nodo non può trasmettere oltre la sua popolazione:
				\begin{equation}
					\sum_j\pi_{ij}=d_i<1
				\end{equation}
				dove $d_i$ indica la capacità di trasmissione (numero di agenti in uscita).
				Si richiede dunque che i flussi siano sempre positivi e che il numero di particelle sia conservato.\\
				Si assuma ora che la velocità di percorrenza sia dipendente dal numero di agenti presenti, quindi
				\begin{equation*}
					\dot{n}_i=\sum_j\pi_{ij}n_j-d_in_i=-L\sum_jL_{ji}n_j
				\end{equation*}
				dove $L_{ji}=d_j\delta_{ji}-\pi_{ji}$ è una matrice laplaciana.
				Le matrici laplaciane possiedono le seguenti proprietà:
				\begin{itemize}
					\item $L_{ji}<0$ se $j\neq i$
					\item $\sum_iL_{ji}=0$
					\item $L_{jj}>0$
				\end{itemize}
				Si nota facilmente come nella matrice laplaciana gli elementi sulla diagonale principale descrivano la capacità di trasporto del sistema, mentre gli elementi esterni alla diagonale descrivano i link.
				Le matrici laplaciane rappresentano di fatto leggi di bilancio di massa, ossia descrivono la mobilitazione da un punto ad un altro del network.\\
				Un sistema di questo tende a rilassare ad un equilibrio: aumentando il numero di agenti in un nodo aumenterà anche la sua capacità di farne uscire.
				Un sistema lineare infatti è insensibile al numero di particelle inserito ma è sensibile a un flusso in entrata variabile: in questo caso il sistema non può rilassare e la sua soluzione dipende dalla velocità di variazione del flusso in entrata.\\
				La terza proprietà della matrice laplaciana garantisce l'integrale del moto
				\begin{equation*}
					\sum_in_i=N
				\end{equation*}
				mentre la seconda garantisce che tutti gli autovalori (eccetto uno che è di certo nullo) siano positivi.
				La dinamica risulta attrattiva verso lo stato di equilibrio, situato evidentemente nel primo quadrante.
				Le proprietà spettrali forniscono il tempo impiegato dal sistema per rilassare.\\
				In generale, si può imporre la congestione con $\pi_{ij}=\pi_{ij}(n_i)$.
				Un risultato simile è ottenibile anche utilizzando la funzione logistica, vedi eq. \ref{equation:funzione_logistica}, utiizzandola come funzione che lega il numero di particelle al peso: all'aumentare di $n$ il peso deve ridursi.
				In questo caso la congestione non si avrà inizialmente ma si creerà rapidamente dopo un certo lasso di tempo.\\
				La congestione in un nodo si propaga facilmente anche ai nodi adiacenti: è dunque possibile creare effetti a cascata che si ripercuotano sul network intero, creando così una dinamica all'indietro.\\
				Per un sistema non lineare a molti gradi di libertà il carico determina la dinamica, quindi il parametro di controllo è il numero di agenti caricato nel sistema.
				\begin{equation*}
					\begin{split}
						\dot{n}_i=\sum_j\pi_{ij}(n_i)n_j-\sum_j\pi_{ij}(n_j)n_i\\
						\sum_in_i=N
					\end{split}
				\end{equation*}
				I problemi di un tale sistema sono:
				\begin{itemize}
					\item studiarne gli stati di equilibrio, il cui numero aumenta con le dimensioni
					\item studiare cosa accade per fluttuazioni (ossia $N=N(t)$)
					\item studiare network $\pi_{ij}$ differenti per evitare le congestioni
					\item ottimizzare il flusso totale $\Phi=\sum_{ij}\pi(n_{i})n_j$
				\end{itemize}
				Tuttavia, per modificare i pesi è necessario trovare dei parametri di controllo, cosa per niente banale.\\
				Spesso una congestione non può essere evitata quindi si tende a gestirla, ossia si cerca di riportare la rete in una situazione di trasporto.\\
				Nel caso lineare la soluzione stazionaria è semplicemente il vettore che indica quanti agenti porre nei vari nodi $\vec{n}=(n_1,\ldots,n_N)$ che soddisfi la condizione
				\begin{equation*}
					\dot{n}=-Ln
				\end{equation*}
				Le fluttuazioni sono inseribili nel sistema sotto forma di random walk, aggiungendo un parametro temperatura.
				Scelto un passo temporale, la transizione $i\to j$ avrà probabilità $\pi_{ij}\Delta t$ di avvenire.
				La probabilità di non muoversi in una determinata direzione è data da $1-\sum_j\pi_{ij}\Delta t$.
				Il passo $\Delta t$ diventa quindi il tempo di evoluzione del sistema (tipicamente piccolo): imporre la linearità rispetto ad esso evita processi non regolari (stocastici).\\
				Una volta trovato l'autovalore nullo $L\bar{n}=0$, la probabilità di trovare la rete in un determinato stato è data da
				\begin{equation}
					P(\vec{n})=\frac{\bar{n}_1^{n_1}\ldots\bar{n}_M^{n_M}}{n_1!\ldots n_M!}M!
				\end{equation}

		\section{Esempi}
			\subsection{Optimal Velocity Model}
				L'OVM è un modello ad agente basato sulle seuguenti equazioni differenziali:
				\begin{equation}
					\begin{cases}
						\dot{x}_i(t)=v_{opt}\left(x_{i+1}(t-\tau)-x_i(t-\tau)\right)\\
						\ddot{x}_i(t)=-\frac{1}{\tau}\left(\dot{x}_i(t)-v_{opt}(x_{i+1}(t)-x_i(t))\right)
					\end{cases}
				\end{equation}
				dove la seconda equazione deriva da $\dot{x}_i(t+\tau)=\dot{x}_i(t)+\ddot{x}_i(t)\tau+o(\tau^2)$.

	% \section{Networks e problemi di trasporto}
	% 	\begin{theorem}
	% 		Un grafico random ha un numero esponenziale di LOOP rispetto ai nodi.
	% 	\end{theorem}
	% 	Corollario: si creano delle \textit{correnti}.
		
\end{document}
