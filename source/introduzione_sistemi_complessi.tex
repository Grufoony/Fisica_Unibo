\documentclass[12pt, a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[main=italian]{babel}
\usepackage{bookmark}
\usepackage[a4paper, total={6in, 9in}]{geometry}
\usepackage{amsmath, amsthm, amssymb, amsfonts}

\theoremstyle{theorem}
\newtheorem{definition}{Definizione}[section]
\newtheorem{theorem}{Teorema}[section]

\begin{document}
	\title{Appunti dal corso Introduzione ai Sistemi Complessi}
	\author{Grufoony}
	\maketitle
	\section{Sistema Complesso}
		\begin{definition}
			\textit{Sistema Complesso} è un sistema dinamico composto da sottosistemi interagenti tra loro.
		\end{definition}
		Per lo studio di un sistema complesso si usa solitamente un approccio olistico, ossia studiando prevalentemente le proprietà macroscopiche del sistema totale, senza considerare i singoli sottosistemi.
		Un'osservazione importante che va effettuata è che un sistema complesso \textbf{prevede}, non descrive.
		Alcune delle proprietà principali sono:
		\begin{itemize}
			\item \textbf{complessità}: presenza di molti d.o.f. (molti sottosistemi)
			\item \textbf{proprietà emergenti}: derivano dal grande numero di sottosistemi. Ad esempio possiamo definire \textit{fluido} un insieme di molte particelle ma la particella singola non può essere fluida.
			\item \textbf{autorganizzazione}: i sistemi complessi sono ibridi, ossia metà stocastici e metà deterministici. Per studiarli devo dare ugual peso a entrambi gli aspetti.
		\end{itemize}
	\section{Distribuzioni}
		Vediamo ora una serie di distribuzioni e teoremi ad esse legati che ci aiuteranno nell'analisi dei sistemi.
		\begin{definition}\hfill
			\begin{itemize}
				\item Gaussiana\\	$\rho(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$
				\item Esponenziale\\	$\rho(x)=\frac{1}{k}e^{-\frac{x}{k}}$
				\item Potenza\\		$\rho(x)\propto\frac{1}{x^a}$, con $a>0$
			\end{itemize}
		\end{definition}
		\begin{definition}
			Momenti di una distribuzione:\\
			$<x^k>=\int_{-\infty}^{+\infty}x^k\rho(x)dx$
		\end{definition}
		\begin{theorem}
			Invarianza di scala:\\
			se $\rho(x)\propto\frac{1}{x^a}$ allora posto $y=\lambda x$ si ha $\rho(y)=\frac{\lambda^a}{x^a}\propto\frac{1}{y^a}$
		\end{theorem}
		\begin{theorem}
			Limite centrale:\\
			Siano ${x_k}$ variabili casuali indipendenti, allora:\\
			$\lim_{N\to\infty}z=\frac{1}{\sqrt{N}}\sum_{k=1}^{N}x_k=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{z^2}{2\sigma^2}}$
		\end{theorem}
		Ora possiamo dare una definizione di probabilità:
		\begin{definition} Probabilità:\\
			$p(x\in[a,b])=\int_{a}^{b}\rho(x)dx$
		\end{definition}
		\begin{definition} Probabilità cumulata:\\
			$p(x\leq a)=\int_{-\infty}^{a}\rho(x)dx$
		\end{definition}
	\section{Informazione ed entropia}
		\begin{definition}
			Una variabile $x$ a valori discreti $\{x_0,x_1,...\}$ è detta variabile di CODING
		\end{definition}
		Considerando una sequenza (\textit{codifica}) $\{x_k\}_1^N$ si può assumere $P(\{x_k\})=p(x_1)...p(x_N)$.
		Una codifica è detta \textbf{ottimale} se può descrivere in maniera univoca un'orbita.
		\begin{definition}
			$-\ln(x)$ informazione portata dal carattere $x$
		\end{definition}
		\begin{definition}
			$S=-\sum_kp(x_k)\ln(p(x_k))$ entropia di informazione (informazione media portata dale variabili $x_k$)
		\end{definition}
		Si nota subito come più un valore della variabile di coding è probabile, minor informazione questo porti.
		Informaticamente, la misura è circa il numero di bit necessari per memorizzare la sequenza.
		Non bisogna confondere entropia con informazione: la variabile deve avere un significato!
		\begin{theorem}
			legge dei grandi numeri\\
			Siano A e B due eventi distinti (osservati N volte), allora si ha che $\lim_{N\to\infty}\frac{p(AB)}{p(A)}=p(B/A)$
		\end{theorem}
		Per capire la sequenza bisogna conoscerne la \textit{memoria}, ossia tutte le dipendenze di un evento dagli altri.
		L'\textit{irreversibilità} di un evento si ha quando la coppia di eventi $AB$ è diversa dalla coppia di eventi $BA$.
		\begin{definition}
			$p_{ij}=p(x_j/x_i)$ matrice stocastica
		\end{definition}
		La matrice stocastica ha per definizione le seguenti proprietà:
		\begin{itemize}
			\item $0\leq p_{ij}\leq 1$
			\item $\sum_jp_{ij}=1$
		\end{itemize}


	\section{Costruzione di un modello}
		Punto fondamentale di un sistema complesso è costruire un modello matematico che riesca a riprodurre le sue caratteristiche fondamentali, per poi studiarlo.
		La prima cosa da definire è l'\textit{ambiente} in cui ci troviamo. Questo può essere neutro o avere caratteristiche, ad esempio una distribuzione di nutrimento (per sistemi biologici).
		Altro punto fondamentale è definire \textit{spazio e tempo}. Spesso non fa differenza la scelta di spazi e tempi discreti rispetto ai continui, quindi è preferibile assumere una discretizzazione iniziale per poi passare al continuo successivamente.
		Una volta definito lo spazio bisogna poi decidere le condizioni al contorno, ossia il comportamento ai bordi. 
		Posso a questo punto avere \textit{barriere} di tre tipi:
		\begin{itemize}
			\item \textbf{riflettenti}, dove ho un bordo \textit{non} oltrepassabile. Si crea quindi un fenomeno di \textbf{attrattività delle pareti}.
			\item \textbf{periodico}, dove ho i bordi coincidenti (esco da una parte e rientro dall'altra). Lo spazio assume in questo caso una forma toroidale.
			\item \textbf{assorbenti}, dove gli oggetti "uscenti" vengono distrutti. In questo caso bisogna di introdurre delle \textit{sorgenti} nel modello per evitare di perdere tutti i soggetti.
		\end{itemize}
		Si nota facilmente come più piccolo sia il modello, più importante sia il contributo degli effetti di bordo.\\
		Nella maggior parte dei sistemi non tutti i soggetti hanno le stesse caratteristiche: si definiscono allora \textbf{classi} di appartenenza, legate tra loro da relazioni matematiche.
		\subsection{Random Walk 1D}
			Il modello più basilare di sistema complesso è sicuramente la random walk su una retta, ossia un punto che ogni istante di tempo decide in maniera casuale se spostarsi a destra o a sinistra.
			Sia $p=\frac{1}{2}$ la probabilità di muoversi verso destra (quindi anche a sinistra) di un passo $\Delta x$. Si hanno:
			\begin{itemize}
				\item \{R\}: $p(t+\Delta t)=x(t)+\Delta x$
				\item \{L\}: $p(t+\Delta t)=x(t)-\Delta x$
			\end{itemize}
			Dopo \textit{n} passi si ha quindi $p(n\Delta t)=x_0+\sum_k\xi_k\Delta x$ con $\xi(t)=\pm 1$.
			Inoltre si può verificare che $<\xi_k>=0$, $<\xi_k^2>=1$, $<\xi_k\xi_h>=<\xi_k><\xi_h>, k\neq h$.
			Per il teorema del limite centrale si ha:
			$\sum_k^n\xi_k\Delta x=\sqrt{n\Delta t}\left(\frac{1}{\sqrt{n}}\sum_k^n\xi_k\right)\frac{\Delta x}{\sqrt{\Delta t}}=\frac{1}{\sqrt{2\pi Dt}}e^{-\frac{z^2}{2Dt}}$, con $z$ variabile gaussiana.
			Introducendo il concetto di diffusione:\\
			\begin{definition}
				Diffusione. $D=\frac{\Delta x^2}{\Delta t}$
			\end{definition}
			si può descrivere l'evoluzione del sistema come $x(t)=x_0+z\sqrt{Dt}$
			Si utilizza $\sqrt{n}$ per normalizzare in quanto è l'unico esponente non divergente.
			La varianza della gaussiana cresce nel tempo, infatti calcolando i momenti della distribuzione si trova $<x(t)>=x_0$, $<(x(t)-x_0)^2>=Dt$.
			Se la topologia del sistema fosse una circonferenza (e non una retta), si avrebbe un rilassamento esponenziale a una situazione stazionaria.
		\subsection{Random Walk 2D}
			Volendo espandere il modello di random walk ad uno spazio 2D si nota subito come, essendo ogni asse indipendente dall'altro, si possa semplicemente comporre due gaussiane:\\
			\begin{equation}
				(x,y)\simeq\frac{1}{2\pi\Delta t}e^{-\frac{x^2+y^2}{2\Delta t}}=\rho(x,y,t)
			\end{equation}
			Dove la diffusione segue la definizione precedente ed è la stessa in tutte le direzioni.
			La funzione $\rho(x,y,t)$ rappresnta di fatto la probabilità che la il soggetto in analisi si trovi in un volume $\Delta x\Delta y$.
			Si può riscrivere la relazione precedente in coorfinate polari ottenendo:
			\begin{equation}
				\rho(r,\theta,t)=\frac{r}{2\pi\Delta t}e^{-\frac{r^2}{2\Delta t}}
			\end{equation}
			studiando più semplicemente l'allontanamento dall'origine.
			In particolare, l'allontanamento medio risulta:
			\begin{equation}
				<r>=\int_0^\infty\rho(r,\theta,t)rdr=\sqrt{\frac{\pi}{2}\Delta t}
			\end{equation}
			e la densità diminuisce quindi esponenzialmente.
		\subsection{Modello Economico}
			Si vuole ora costruire un primo modello legato alla realtà simulando, per quanto grossolanamente, l'economia globale.\\
			Supponiamo di avere \textit{M} individui con \textit{n} soldi ciascuno, che si muovono su una griglia secondo una Random Walk 2D.
			Ogni qualvolta due individui si trovino sulla stessa cella questi si scambiano 1 soldo con probabilità $p=\frac{1}{2}$.
			\textbf{Caso limite}: se si incontra un povero ($n=0$), si gioca lo stesso (gioco scorretto) per permettere a tutti di uscire dalla povertà.
			Il sistema ha quindi i seguenti limiti:
			\begin{equation}
				\begin{cases}
					\sum_kn_k=N\\
					n_k\geq 0
				\end{cases}
			\end{equation}
			con \textit{N} costante, quindi non si ha creazione/distruzione di denaro.
			La probabilità di trovare un individuo con n soldi è:
			\begin{equation}
				p(n)=\frac{\binom{M+N-2-n}{M-2}}{\binom{M+N-1}{N-1}}
			\end{equation}
			e, ponendo $\overline{n}=\frac{N}{M}$, si può calcolare:
			\begin{equation}
				\lim_{M\to\infty}\frac{1}{\overline{n}}\left( 1-\frac{n}{M}\right)^M=\frac{1}{\overline{n}}e^{-\frac{n}{\bar{n}}}
			\end{equation}
			quindi la probabilità segue una decrescita esponenziale.\\
			Il modello prevede quindi:
			\begin{itemize}
				\item molti poveri e pochi ricchi (ma praticamente nessun super-ricco)
				\item esiste un tempo in cui un povero diventa ricco (e viceversa)
				\item simile alla distribuzione di energia di Maxwell-Boltzmann
				\item se chi è ricco pagasse di più si otterrebbe una curva a campana
			\end{itemize}
			Tuttavia osservando i dati sperimentali si nota una discrepanza: nella realtà la probabilità sembra seguire una legge a potenza piuttosto che esponenziale.
		\subsection{Modello Economico Evoluto}
			Per adattare il modello precedente alla realtà si introduce una microdinamica sugli scambi di denaro.\\
			Sia $\pi_\pm$ la probabilità di guadagnare $\pm 1$ soldi se un soggetto ne possiede \textit{n}. All'equilibrio si deve avere:
			\begin{equation}
				\pi_+(n-1)p(n-1)+\pi_-(n+1)p(n+1)=\pi_+(n)p(n)+\pi_-(n)p(n)
			\end{equation}
			e in particolare è verificato il \textit{bilancio dettagliato}:
			\begin{equation}
				\pi_+(n-1)p(n-1)\pi_+(n)p(n)=0
			\end{equation}
			Si possono ora ipotizzare le seguenti dipendenze:
			\begin{equation}
				\begin{cases}
					\pi_+(n-1)-\pi_-(n)\simeq a\\
					\frac{\pi_+(n-1)+\pi_-(n)}{2}\simeq bn
				\end{cases}
			\end{equation}
			Sviluppando con Taylor ed effettuando qualche calcolo si può procedere:
			\begin{equation}
				ap(n)+\frac{\partial}{\partial n}(bn)p(n)=0
			\end{equation}
			\begin{equation}
				-\frac{a}{bn}=\frac{1}{(nb)p(n)}\frac{\partial}{\partial n}(bn)p(n)
			\end{equation}
			\begin{equation}
				-\frac{a}{b}\ln(n)=\ln(bn)p(n) + const
			\end{equation}
			In conclusione:
			\begin{equation}
				p(n)\propto\frac{1}{b}\frac{1}{n^{\frac{a}{b}+1}}
			\end{equation}
			e si ottiene l'andamento a potenza.
		\subsection{La rovina di un giocatore}
			Consideriamo un giocatore d'azzardo con a disposizione un capitale \textit{k} e che vuole arrivare ad un capitale \textit{M}.
			Il gioco finisce ai "bordi" per $k=0$ (giocatore rovinato) o per $k=M$ (giocatore felice).
			Siano $p$ la probabilità di guadagnare, $q=1-p$ la probabilità di perdere, $P_M(k)$ la probabilità di arrivare al capitale \textit{M} partendo da \textit{k}.
			Come nel modello economico evoluto si ha:
			\begin{equation}
				P_M(k)=pP_M(k+1)+qP_M(k-1)
			\end{equation}
			con i vincoli
			\begin{equation}
				\begin{cases}
					P_M(0)=0\\
					P_M(M)=1
				\end{cases}
			\end{equation}
			Ragionando per induzione si ottiene:
			\begin{equation}
				P_M(k+1)-P_M(k)=\frac{q}{p}\left[P_M(k)-P_M(k-1)\right]=\left(\frac{q}{p}\right)^kP_M(1)
			\end{equation}
			\begin{equation}
				P_M(k)=\frac{1-\left(\frac{q}{p}\right)^k}{1-\left(\frac{q}{p}\right)^M}
			\end{equation}
			Ponendo ora $p>q$,
			\begin{equation}
				P_\infty(k)=1-\left(\frac{q}{p}\right)^k
			\end{equation}
			In particolare, considerando un gioco equo, si può notare come $P_M(k)=\frac{k}{M}$ e quindi:
			\begin{itemize}
				\item il gioco è alla pari solo se $k\simeq M$
				\item la probabilità di vincita aumenta all'aumentare del proprio capitale rispetto a quello avversario
				\item contro un casinò ($M\to\infty$) la probabilità di vincita è evidentemente nulla anche in caso di gioco equo (assunzione oltretutto inverosimile)
			\end{itemize}

\end{document}